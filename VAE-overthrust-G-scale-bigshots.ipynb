{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c370f01b-6df5-4369-9190-a0ee19894040",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.insert(1, './codes/codes')  # insert at 1, 0 is the script path (or '' in REPL)\n",
    "\n",
    "print(\"----------------\")\n",
    "!python --version\n",
    "!nvidia-smi\n",
    "print(\"----------------\")\n",
    "print(\"System Version: \", sys.version)\n",
    "\n",
    "## ======================================================== ##\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from plot_functions import add_colorbar, imagesc\n",
    "\n",
    "print(\"PyTorch Version: \", torch.__version__)\n",
    "print(\"----------------\")\n",
    "print(\"torch.cuda.is_available: \",torch.cuda.is_available())\n",
    "print(\"----------------\")\n",
    "print(torch.__version__, torch.version.cuda, torch.cuda.get_device_name(0))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# deterministic behavior\n",
    "torch.manual_seed(3)\n",
    "torch.cuda.manual_seed_all(3)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(3)\n",
    "# random.seed(3)\n",
    "os.environ['PYTHONHASHSEED'] = str(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84b829f-b36d-4d87-b4c9-eace6ae949e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deterministic behavior\n",
    "def seed_everything(seed):\n",
    "    import os\n",
    "    import torch\n",
    "    import random\n",
    "    import numpy as np\n",
    "    random.seed(seed)            # Python random module\n",
    "    np.random.seed(seed)         # Numpy Module\n",
    "    torch.manual_seed(seed)      # Current CPU\n",
    "    torch.cuda.manual_seed(seed) # Current GPU\n",
    "    torch.cuda.manual_seed_all(seed) # All GPU\n",
    "    torch.backends.cudnn.benchmark = False    # Close Optimization\n",
    "    torch.backends.cudnn.deterministic = True # Close Optimization\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "\n",
    "# 设置一个种子\n",
    "seed = 37\n",
    "# 调用函数以设置种子\n",
    "seed_everything(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a131e5-f734-4a36-a115-3637406642b0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file = np.load(\"./SEGoverthrust.npz\")\n",
    "vel3d = file['vmodel'].transpose(1, 0, 2)/1000  #z, x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe474dc-f7c9-4e36-b202-4617ddcaf969",
   "metadata": {},
   "outputs": [],
   "source": [
    "vel3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aaccfb-585c-491b-a202-529015879f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.ndimage import gaussian_filter\n",
    "vmodel = np.array(pd.read_csv(\"./vel_marmousi_376x1151.csv\")) \n",
    "vmodel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c640fee9-ffa3-4da4-b35e-742c19f0c6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "file = np.load(\"./SEGoverthrust.npz\")\n",
    "vel3d = file['vmodel'].transpose(1, 0, 2)\n",
    "vmodel = vel3d[:, 100, :]\n",
    "v_init = gaussian_filter(vmodel, sigma=15)\n",
    "\n",
    "dz = 8\n",
    "nz, nx = vmodel.shape\n",
    "print(\"Original Model Shape: {}, Grid Interval: {}m\".format(vmodel.shape, dz))\n",
    "\n",
    "################# Plot true & initial velocity model #################\n",
    "fig = plt.figure(figsize=(12, 2))\n",
    "gs = fig.add_gridspec(1, 2)\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\")\n",
    "im = ax.imshow(vmodel/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1.3, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 1])\n",
    "ax.set( xlabel=\"Distance x[km]\")\n",
    "im = ax.imshow(v_init/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1.3, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "################# Plot true & initial velocity model #################\n",
    "\n",
    "dz = 25\n",
    "vp_tensor_init = torch.from_numpy(vmodel).type(dtype=torch.float32).to(device)\n",
    "vi_tensor_init = torch.from_numpy(v_init).type(dtype=torch.float32).to(device)\n",
    "print(vp_tensor_init.shape)\n",
    "vp_tensor = vp_tensor_init[None, 0:128, 0:768:3]\n",
    "vi_tensor = vi_tensor_init[None, 0:128, 0:768:3]\n",
    "\n",
    "vi_tensor = torch.from_numpy(gaussian_filter(vi_tensor.cpu().numpy(), sigma=13)).type(dtype=torch.float32).to(device)\n",
    "\n",
    "nv, nz, nx = vp_tensor.shape\n",
    "print(\"Resampled Model Shape: {}, Grid Interval: {}m\".format((nz, nx), dz))\n",
    "\n",
    "# Setting locations of sources and receivers\n",
    "xs = torch.arange(15, nx-10, 13, dtype=torch.long).repeat([nv, 1])      # x-coordinate for sources\n",
    "ns = xs.shape[1]                                                        # number of shots \n",
    "xr = torch.arange(0, nx, 1, dtype=torch.long).repeat([nv, ns, 1])       # x-coordinate for receivers\n",
    "zs = torch.full((nv, ns), 0, dtype=torch.long)                          # depth of sources    震源深度\n",
    "zr = torch.full((nv, ns, nx), 0, dtype=torch.long)                      # depth of receivers 地表\n",
    "print(\"Number of shots: {}, with interval: {}m, in depth: {}m\".format(ns, (xs[0, 1]-xs[0, 0])*dz, zs[0, 0]*dz))\n",
    "print(xs)\n",
    "\n",
    "################# Plot true & initial velocity model #################\n",
    "fig = plt.figure(figsize=(12, 2))\n",
    "gs = fig.add_gridspec(1, 2)\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\")\n",
    "im = ax.imshow(vp_tensor[0].cpu().numpy()/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=0.8, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 1])\n",
    "ax.set( xlabel=\"Distance x[km]\")\n",
    "im = ax.imshow(vi_tensor[0].cpu().numpy()/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=0.8, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "# ################# Plot true & initial velocity model #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a8c50c-734b-4750-aa0d-8e01f39630bc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vp_tensor.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23254da7-d922-4e5b-b20f-9fae5e13f9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_tensor.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d4d7ae-2493-4bc9-a8e1-89c2f221e354",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rnn_fd import rnn2D\n",
    "from generator_old import wGenerator #单频雷克子波\n",
    "\n",
    "freeSurface = True                                                      # free surface option for forward modeling\n",
    "npad = 15                                                               # velocity padding in grid points\n",
    "freq = 6                                                              # dominant frequency of wavelet in Hz\n",
    "dt = 0.003                                                            # time samling interval, fixed for all shots gathers\n",
    "nt = 1024                                                              # number of samples in time\n",
    "\n",
    "t = dt * torch.arange(0, nt, dtype=torch.float32)                       # create time vector\n",
    "wavelet = wGenerator(t, freq).ricker().to(device)                       # generate wavelet\n",
    "nx_pad = nx + 2 * npad\n",
    "nz_pad = nz + npad if freeSurface else nz + 2 * npad\n",
    "f = np.arange(0, nt/2+1) / (nt*dt)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 2.5))\n",
    "gs = fig.add_gridspec(1, 2)\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "ax.set(xlabel=\"$Time$\", ylabel=\"$Amp$\", title=\"$Ricker$\", xlim=[0, 1])\n",
    "ax.plot(t, wavelet.cpu().numpy(), color='red', linestyle='-', linewidth=1.5)\n",
    "ax.grid(True, which='both', linestyle='--', color='grey', linewidth=.8, alpha=1.0)\n",
    "ax.minorticks_on()\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 1])\n",
    "ax.set(xlabel=\"$Frequency [Hz]$\", ylabel=\"$Amp$\", title=\"$Amp Spectrum$\", xlim=[0, 40])\n",
    "ax.plot(f, np.abs(torch.fft.rfft(wavelet).cpu().numpy()), color='red', linestyle='-', linewidth=1.5)\n",
    "ax.grid(True, which='both', linestyle='--', color='grey', linewidth=.8, alpha=1.0)\n",
    "ax.minorticks_on()\n",
    "\n",
    "################## Check the stability condition #################\n",
    "print(vp_tensor.max()*dt/dz/np.sqrt(1/2),\"< 1\") # should <1\n",
    "print(vp_tensor.min()/10/freq/dz,\"> 1\") # should >1\n",
    "\n",
    "forward_rnn = rnn2D(nz, nx, zs, xs, zr, xr, dz, dt, \n",
    "                    npad=npad, order=2, vmax=vp_tensor.max(), \n",
    "                    log_para=1e-6,\n",
    "                    freeSurface=True, \n",
    "                    dtype=torch.float32, \n",
    "                    device=device).to(device)\n",
    "\n",
    "# forward modeling\n",
    "# _, _, shots, _ = forward_rnn(vmodel=vp_tensor.to(device), segment_wavelet=wavelet)\n",
    "# _, _, shots_init, _ = forward_rnn(vmodel=vi_tensor.to(device), segment_wavelet=wavelet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2861146a-830d-47b7-a403-266f6bee134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(shots, \"./shots_overthrust_scale1024_big4Hz.npz\")\n",
    "shots = torch.load(\"./shots_overthrust_scale1024_big4Hz.npz\", weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b71dbc-f8b9-413d-afe4-229328df18b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(ns*1.5, 8))\n",
    "imagesc(fig,\n",
    "        shots.cpu().numpy().reshape(-1, ns, nt, nx),\n",
    "        vmin=-shots.max()/50,\n",
    "        vmax=shots.max()/50,\n",
    "        extent=[0, nx*dz/1000, t.numpy().max(), 0],\n",
    "        aspect=4,\n",
    "        nRows_nCols=(1, 6),\n",
    "        cmap='RdBu_r', #seismic\n",
    "        ylabel=\"Time[s]\",\n",
    "        xlabel=\"Position[km]\",\n",
    "        clabel=\"\",\n",
    "        xticks=np.arange(0., int(nx*dz/1000), 2),\n",
    "        yticks=np.arange(0., t.numpy().max(), .5),\n",
    "        fontsize=15,\n",
    "        cbar_width=\"7%\",\n",
    "        cbar_height=\"100%\",\n",
    "        cbar_loc='lower left')\n",
    "fig.tight_layout(pad=-0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f92305-2a18-4f1e-81b4-410afba88212",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VAE\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, k_size=3, stride=1, padding=1):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(nn.Conv2d(in_channels, \n",
    "                                             out_channels, \n",
    "                                             kernel_size=k_size, \n",
    "                                             stride=stride, \n",
    "                                             padding=padding),\n",
    "                                   nn.BatchNorm2d(out_channels),\n",
    "                                   nn.LeakyReLU()\n",
    "                                  )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class TransConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, k_size=3, stride=2, padding=1):\n",
    "        super(TransConvBlock, self).__init__()\n",
    "        \n",
    "        self.transconv = nn.Sequential(nn.ConvTranspose2d(in_channels, \n",
    "                                                          out_channels, \n",
    "                                                          kernel_size=k_size, \n",
    "                                                          stride=stride, \n",
    "                                                          padding=padding),\n",
    "                                       nn.BatchNorm2d(out_channels),\n",
    "                                       nn.LeakyReLU()\n",
    "                                       )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.transconv(x)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class TransConvBlock_last(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, k_size=3, stride=2, padding=1):\n",
    "        super(TransConvBlock_last, self).__init__()\n",
    "        \n",
    "        self.transconv = nn.Sequential(nn.ConvTranspose2d(in_channels, \n",
    "                                                          out_channels, \n",
    "                                                          kernel_size=k_size, \n",
    "                                                          stride=stride, \n",
    "                                                          padding=padding),\n",
    "                                       nn.BatchNorm2d(out_channels)\n",
    "                                       )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.transconv(x)\n",
    "        return out\n",
    "        \n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        super(MyModel, self).__init__()    \n",
    "        \n",
    "        #encoder--------------------------------------------                                   \n",
    "        self.conv_block_1 = ConvBlock(18, 32, k_size=(4,1), stride=(2,1), padding=(1,0))     \n",
    "        self.conv_block_2 = ConvBlock(32, 64, k_size=(4,1), stride=(2,1), padding=(1,0)) \n",
    "        self.conv_block_3 = ConvBlock(64, 128, k_size=4, stride=2, padding=1)          \n",
    "        self.conv_block_4 = ConvBlock(128, 256, k_size=4, stride=2, padding=1)         \n",
    "        self.conv_block_5 = ConvBlock(256, 512, k_size=4, stride=2, padding=1)      \n",
    "        self.conv_block_6 = ConvBlock(512, 512, k_size=4, stride=2, padding=1)   \n",
    "        \n",
    "        #decoder--------------------------------------------     \n",
    "        self.trans_conv_block_1 = TransConvBlock(512, 256, k_size=(1,4), stride=(1,2), padding=(0,1))                \n",
    "        self.trans_conv_block_2 = TransConvBlock(256, 128, k_size=4, stride=2, padding=1)                \n",
    "        self.trans_conv_block_3 = TransConvBlock(128, 64, k_size=4, stride=2, padding=1)                \n",
    "        self.trans_conv_block_4 = TransConvBlock(64, 32, k_size=4, stride=2, padding=1)                      \n",
    "        self.trans_conv_block_5 = TransConvBlock_last(32, 1, k_size=3, stride=1, padding=1)                \n",
    "\n",
    "        self.fc_mu = nn.Linear(16*16*512, latent_dim)\n",
    "        self.fc_var = nn.Linear(16*16*512, latent_dim)\n",
    "        self.decoder_input = nn.Linear(latent_dim, 16*16*512)\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.conv_block_2(x)\n",
    "        x = self.conv_block_3(x)\n",
    "        x = self.conv_block_4(x)\n",
    "        x = self.conv_block_5(x)    \n",
    "        result = self.conv_block_6(x)    \n",
    "        result = torch.flatten(result, start_dim=1)\n",
    "        mu = self.fc_mu(result)\n",
    "        log_var = self.fc_var(result)\n",
    "        \n",
    "        return mu, log_var\n",
    "        \n",
    "        \n",
    "    def decode(self, x):\n",
    "        x = self.decoder_input(x)\n",
    "        x = x.view(1, 512, 16, 16)\n",
    "        x = self.trans_conv_block_1(x)\n",
    "        x = self.trans_conv_block_2(x)\n",
    "        x = self.trans_conv_block_3(x)\n",
    "        x = self.trans_conv_block_4(x)\n",
    "        x = self.trans_conv_block_5(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        \"\"\"\n",
    "        Reparameterization trick to sample from N(mu, var) from\n",
    "        N(0,1).\n",
    "        :param mu: (Tensor) Mean of the latent Gaussian [B x D]\n",
    "        :param logvar: (Tensor) Standard deviation of the latent Gaussian [B x D]\n",
    "        :return: (Tensor) [B x D]\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps * std + mu\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        v_pred = self.decode(z)  \n",
    "        \n",
    "        return v_pred, mu, log_var\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd58d550-dabf-4916-9280-fd54e3a09c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "model = MyModel()\n",
    "inputs = (1, 18, 1024, 256)\n",
    "summary(model, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cb0777-e2f2-49e8-a033-3ca5b293a368",
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_tensor.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1a1149-33d9-4182-9398-ba9d67fe5810",
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_tensor.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca851c7f-5fda-403b-84ee-134d2fb08d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_tensor_norm = (vp_tensor - 3800)/800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566971b4-dc44-40d4-be25-c233a6c68cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 7))\n",
    "gs = fig.add_gridspec(2, 2)\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"vp_tensor\")\n",
    "im = ax.imshow((vp_tensor[0].cpu().detach().numpy())/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "# 设置colorbar的取值范围\n",
    "vmin = (vp_tensor[0]/1000).min() # 最小值\n",
    "vmax = ((vp_tensor[0])/1000).max()   # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 1])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"vp_tensor_norm\")\n",
    "im = ax.imshow((vp_tensor_norm[0].cpu().detach().numpy()), extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "# 设置colorbar的取值范围\n",
    "vmin = (vp_tensor_norm[0]).min() # 最小值\n",
    "vmax = (vp_tensor_norm[0]).max() # 最大值\n",
    "im.set_clim(vmin, vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d12fd8-034b-4bb6-81ac-5190ba011d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "# torchvision.models.vgg16().features\n",
    "\n",
    "def train(model_Jin, data, wavelet, vi_tensor, optimizer, device='cpu'):\n",
    "    \n",
    "    data_resample = data[:, :, :, :]   #输入的是resample后的\n",
    "    data_norm = (data_resample-data.mean())/(data.std()).to(device)\n",
    "   \n",
    "    train_loss = 0\n",
    "    data_norm = data_norm.to(device)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    v_recon_norm, mu, logvar = model_Jin(data_norm) \n",
    "    v_recon = (v_recon_norm)*(1000) + 2900  \n",
    "    v_recon = v_recon.to(device).type(dtype=torch.float32)\n",
    "    \n",
    "    loss_fn2 = nn.MSELoss()\n",
    "    Loss2 = loss_fn2(v_recon[0], vi_tensor)\n",
    "    loss = Loss2\n",
    "    \n",
    "    train_loss += loss.detach().cpu().item()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return [train_loss], v_recon[0], data\n",
    "\n",
    "def save_state(epoch, model, optimizer, train_loss_history):\n",
    "    import os\n",
    "    state = {'epoch': epoch + 1,\n",
    "             'train_loss_history': train_loss_history,\n",
    "             'state_dict': model.state_dict(),\n",
    "             'optimizer': optimizer.state_dict()\n",
    "             }\n",
    "    torch.save(state, \"./checkpoints-VAE-overthrust-G-scale/checkpoint-VAE-pre-overthrust-1-{}.pth\".format(epoch+1))\n",
    "    if os.path.exists(\"./checkpoints-VAE-overthrust-G-scale/checkpoint-VAE-pre-overthrust-1-{}.pth\".format(epoch)):\n",
    "        os.remove(\"./checkpoints-VAE-overthrust-G-scale/checkpoint-VAE-pre-overthrust-1-{}.pth\".format(epoch))\n",
    "\n",
    "def load_state(model, optimizer, resume_file):\n",
    "    checkpoint = torch.load(resume_file)\n",
    "    resume_epoch = checkpoint['epoch']\n",
    "    train_loss_history = checkpoint['train_loss_history']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    return resume_epoch, model, optimizer, train_loss_history   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd001ae-8573-4c9e-bb6b-0bcd3b5c0b38",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "# 训练模型\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "data = torch.load(\"./shots_overthrust_scale1024_big4Hz.npz\").to(device).type(dtype=torch.float32)  #[1,12,1024,256]\n",
    "\n",
    "model = MyModel().to(device)\n",
    "optimizer = torch.optim.Adam([{'params': model.parameters()}], \n",
    "                               lr=0.0001, weight_decay=0.0001)\n",
    "\n",
    "max_epoch = 1000\n",
    "train_loss_history = []\n",
    "print_interval = 5\n",
    "for epoch in range(0, max_epoch):\n",
    "   \n",
    "    train_loss, v_pred, s_pred  = train(model, data, wavelet, vi_tensor, optimizer, device)\n",
    "    train_loss_history.append(train_loss)\n",
    "    save_state(epoch, model, optimizer, train_loss_history)\n",
    "   \n",
    "    if (epoch + 1) % print_interval == 0:  #取余数是否等于0\n",
    "        print(\"Epoch: {}, Training Loss: {:.8f}\".format(epoch, train_loss[0]))\n",
    "\n",
    "train_loss_history = torch.tensor(train_loss_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e80ad1-4d27-4455-a21c-d23620f77cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 7))\n",
    "gs = fig.add_gridspec(2, 2)\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"v_pred_full\")\n",
    "im = ax.imshow((v_pred[0].cpu().detach().numpy())/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "# 设置colorbar的取值范围\n",
    "vmin = (vi_tensor[0]/1000).min() # 最小值\n",
    "vmax = ((vi_tensor[0])/1000).max()   # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(gs[1, 0])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"vi\")\n",
    "im = ax.imshow(((vi_tensor[0]).cpu().detach().numpy() )/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(gs[1, 1])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"loss\")\n",
    "im = ax.imshow(((v_pred[0]-vi_tensor[0]).cpu().detach().numpy() )/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "# 设置colorbar的取值范围\n",
    "vmin = -((v_pred[0]-vi_tensor[0])/1000).max()  # 最小值\n",
    "vmax = ((v_pred[0]-vi_tensor[0])/1000).max()   # 最大值\n",
    "im.set_clim(vmin, vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe499d1-3dd6-465f-8e91-466cbb5beaed",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, data, wavelet, vp_tensor, optimizer, device='cpu'):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    model.train()\n",
    "    \n",
    "    lamda1 = lamda2 = lamda3 = lamda4 = 1\n",
    "    \n",
    "    data_resample = data[:, :, :, :] \n",
    "    data_norm = (data_resample-data.mean())/(data.std()).to(device)\n",
    "    \n",
    "    train_loss = 0\n",
    "    Loss_val = 0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    v_recon_norm, mu, logvar= model(data_norm) \n",
    "    v_recon = (v_recon_norm)*(800) + 3800  \n",
    "    \n",
    "    v_recon[v_recon < 2300] = 2300\n",
    "    v_recon[v_recon > 5500] = 5500\n",
    "    v_recon[torch.isnan(v_recon)] = 0\n",
    "    v_recon[v_recon == float('inf')] = 0\n",
    "\n",
    "    _, _, shots, _ = forward_rnn(vmodel = v_recon[0].to(device), segment_wavelet=wavelet)\n",
    "    shots[torch.isnan(shots)] = 0\n",
    "    shots[shots == float('inf')] = 0\n",
    "    shots_resample = shots[:, :, :, :]\n",
    "\n",
    "    data_rgb = data_resample[0][:,None,].repeat(1, 3, 1, 1)    \n",
    "    shots_rgb = shots_resample[0][:,None,].repeat(1, 3, 1, 1)  \n",
    "    data_rgb_norm = (data_rgb-data_rgb.mean())/(data_rgb.std()) \n",
    "    shots_rgb_norm = (shots_rgb-data_rgb.mean())/(data_rgb.std())\n",
    "    data_vgg = model_vgg(data_rgb_norm)\n",
    "    shots_vgg = model_vgg(shots_rgb_norm)\n",
    "    \n",
    "    loss_fn1 = nn.L1Loss()\n",
    "    loss_fn2 = nn.MSELoss()\n",
    "   \n",
    "    Loss1 = loss_fn1(data_resample, shots_resample)\n",
    "    Loss2 = loss_fn2(data_resample, shots_resample)\n",
    "    L_recon_pixel = lamda1*Loss1 + lamda2*Loss2\n",
    "    \n",
    "    Loss3 = loss_fn1(data_vgg, shots_vgg)\n",
    "    Loss4 = loss_fn2(data_vgg, shots_vgg)\n",
    "    L_recon_perceptual = lamda3*Loss3 + lamda4*Loss4\n",
    "    \n",
    "    KLD = -0.5 * torch.sum(1 + torch.log((torch.exp(0.5 * logvar)).pow(2)) - mu.pow(2) - (torch.exp(0.5 * logvar)).pow(2))  #先验 N(0,1)\n",
    "\n",
    "    loss = L_recon_pixel + L_recon_perceptual + KLD\n",
    "    \n",
    "    train_loss += loss.detach().cpu().item()\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    loss_fn2 = nn.MSELoss()\n",
    "    Loss_val = loss_fn2(v_recon[0], vp_tensor)\n",
    "    Loss_val += Loss_val.detach().cpu().item()\n",
    "    return [train_loss, L_recon_pixel, L_recon_perceptual, KLD, Loss_val], v_recon[0], shots, mu, logvar \n",
    "\n",
    "\n",
    "def test(model, data, device='cpu'):\n",
    "    model.eval()\n",
    "    data_resample = data[:, :, :, :]  \n",
    "    data_norm = (data_resample-data.mean())/(data.std()).to(device)\n",
    "    \n",
    "    v_recon_norm, mu, logvar= model(data_norm)\n",
    "    v_recon = (v_recon_norm)*(800) + 3800  \n",
    "   \n",
    "    return v_recon[0], mu, logvar \n",
    "    \n",
    "def save_state(epoch, model, optimizer, train_loss_history):\n",
    "    import os\n",
    "    state = {'epoch': epoch + 1,\n",
    "             'train_loss_history': train_loss_history,\n",
    "             'state_dict': model.state_dict(),\n",
    "             'optimizer': optimizer.state_dict()\n",
    "             }\n",
    "    torch.save(state, \"./checkpoints-VAE-overthrust-G-scale/checkpoint-VAE-overthrust-1-{}.pth\".format(epoch+1))\n",
    "    if os.path.exists(\"./checkpoints-VAE-overthrust-G-scale/checkpoint-VAE-overthrust-1-{}.pth\".format(epoch)):\n",
    "        os.remove(\"./checkpoints-VAE-overthrust-G-scale/checkpoint-VAE-overthrust-1-{}.pth\".format(epoch))\n",
    "        \n",
    "def load_state(model, optimizer, resume_file):\n",
    "    checkpoint = torch.load(resume_file)\n",
    "    resume_epoch = checkpoint['epoch']\n",
    "    train_loss_history = checkpoint['train_loss_history']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    return resume_epoch, model, optimizer, train_loss_history   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bcfcde-222a-42c3-a7dd-fc3de098cc59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision\n",
    "\n",
    "# 训练模型\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "data = torch.load(\"./shots_overthrust_scale1024_big4Hz.npz\").to(device).type(dtype=torch.float32)\n",
    "\n",
    "model = MyModel().to(device)\n",
    "optimizer = torch.optim.Adam([{'params': model.parameters()}], \n",
    "                               lr=0.0001, weight_decay=0.0001)\n",
    "_, model, _, _ = load_state(model, optimizer, \"./checkpoints-VAE-overthrust-G-scale/checkpoint-VAE-pre-overthrust-1-1000.pth\") \n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.AdamW([{'params': model.parameters()}], \n",
    "                               lr=0.00001, betas=(0.9, 0.999), weight_decay=0.0001)\n",
    "\n",
    "model_vgg = torchvision.models.vgg16(pretrained=True).features[:13].to(device) #第13层输出--conv5的结果。\n",
    "\n",
    "max_epoch = 3000\n",
    "train_loss_history = [[], [], [], [], []] \n",
    "print_interval = 1\n",
    "save_interval = 100\n",
    "for epoch in range(0, max_epoch):\n",
    "   \n",
    "    train_loss, v_pred, s_pred, mu, logvar = train(model, data, wavelet, vp_tensor, optimizer, device)\n",
    "    for i in range(5):\n",
    "        train_loss_history[i].append(train_loss[i]) \n",
    "      \n",
    "    if epoch == 0 or (epoch < 100 and (epoch + 1) % 10 == 0) or (epoch >= 100 and (epoch + 1) % 100 == 0):\n",
    "        save_state(epoch, model, optimizer, train_loss_history)\n",
    "    \n",
    "    if (epoch + 1) % print_interval == 0:\n",
    "        print(\"Epoch: {}, Training Loss: {:.8f}, recon_pixel Loss: {:.8f}, recon_perceptual Loss: {:.8f}, KLD Loss: {:.8f}, recon_vmodel Loss: {:.8f}\".format(epoch, train_loss[0], train_loss[1], train_loss[2], train_loss[3], train_loss[4]))\n",
    "\n",
    "train_loss_history = torch.tensor(train_loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550f3f91-3443-4d62-a4dc-fc2b666c76fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_history = torch.tensor(train_loss_history)\n",
    "train_loss_history.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb19708-ae5c-4e21-929f-0c3bc07f4c02",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n=3000\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 1, 1)\n",
    "# plt.plot(np.arange(0,n), train_loss_history[0,0:n].numpy(), label=\"all\")\n",
    "plt.plot(np.arange(0,n), train_loss_history[1,0:n].numpy(), label=\"recon_pixel\")\n",
    "plt.plot(np.arange(0,n), train_loss_history[2,0:n].numpy(), label=\"recon_percep\")\n",
    "plt.plot(np.arange(0,n), train_loss_history[3,0:n].numpy(), label=\"KLD\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fab7e3-e4a0-43f4-a0ec-6ffc1418d57b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n=300\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.plot(np.arange(0,n), np.log(train_loss_history[3,0:n].numpy())/1000, label=\"KLD\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b04032-f063-4708-9b71-4bf614e213c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3000\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.plot(np.arange(0,n), train_loss_history[4,0:n].numpy(), label=\"recon_vp\")\n",
    "\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1718c9-53fa-4c23-96be-3652e7f25e30",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 15))\n",
    "gs = fig.add_gridspec(3, 2)\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"v_pred\")\n",
    "im = ax.imshow((v_pred[0].cpu().detach().numpy())/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "# 设置colorbar的取值范围\n",
    "vmin = ((vp_tensor[0])/1000).min()  # 最小值\n",
    "vmax = ((vp_tensor[0])/1000).max()  # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "\n",
    "ax = fig.add_subplot(gs[1, 1])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"vp\")\n",
    "im = ax.imshow(((vp_tensor[0]).cpu().detach().numpy() )/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "# 设置colorbar的取值范围\n",
    "vmin = ((vp_tensor[0])/1000).min()  # 最小值\n",
    "vmax = ((vp_tensor[0])/1000).max()  # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "\n",
    "ax = fig.add_subplot(gs[1, 0])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"vi\")\n",
    "im = ax.imshow(((vi_tensor[0]).cpu().detach().numpy() )/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "vmin = ((vp_tensor[0])/1000).min()  # 最小值\n",
    "vmax = ((vp_tensor[0])/1000).max()  # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "\n",
    "ax = fig.add_subplot(gs[2, 1])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"v_pred-vp\")\n",
    "im = ax.imshow(((v_pred[0]-vp_tensor[0]).cpu().detach().numpy() )/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "# 设置colorbar的取值范围\n",
    "vmin = -((v_pred[0]-vp_tensor[0])/1000).max()  # 最小值\n",
    "vmax = ((v_pred[0]-vp_tensor[0])/1000).max()   # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(gs[2, 0])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"v_pred-vi\")\n",
    "im = ax.imshow(((v_pred[0]-vi_tensor[0]).cpu().detach().numpy() )/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "# 设置colorbar的取值范围\n",
    "vmin = -((v_pred[0]-vi_tensor[0])/1000).max()   # 最小值\n",
    "vmax = ((v_pred[0]-vi_tensor[0])/1000).max()   # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f07ce81-4be2-4f3f-b531-baa60eec1aa2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision\n",
    "\n",
    "# 训练模型\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "data = torch.load(\"./shots_overthrust_scale1024.npz\").to(device).type(dtype=torch.float32)  #[1,12,1024,256]\n",
    "\n",
    "model = MyModel().to(device)\n",
    "optimizer = torch.optim.AdamW([{'params': model.parameters()}], \n",
    "                               lr=0.00001, betas=(0.9, 0.999), weight_decay=0.0001)\n",
    "\n",
    "_, model, _, train_loss_history = load_state(model, optimizer, \"./checkpoints-VAE-overthrust-G-scale/checkpoint-VAE-overthrust-1-3000.pth\") \n",
    "model_vgg = torchvision.models.vgg16(pretrained=True).features[:13].to(device) #第13层输出--conv5的结果。\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b996d96b-2564-4938-83aa-45a9dcab4426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data, device='cpu'):\n",
    "    model.eval()\n",
    "    data_resample = data[:, :, :, :]   #输入的是resample后的\n",
    "    data_norm = (data_resample-data.mean())/(data.std()).to(device)\n",
    "    with torch.no_grad():\n",
    "        v_recon_norm, mu, logvar= model(data_norm)  #输出范围[-1,1]\n",
    "        v_recon = (v_recon_norm)*(800) + 3800  \n",
    "    return v_recon[0], mu, logvar \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5f58bf-0edd-473c-8dc3-072985069cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 500\n",
    "v_samp = torch.zeros((samples, 128, 256))\n",
    "for s in range(samples):\n",
    "    v_pred, _, _ = test(model, data, device)\n",
    "    v_samp[s] = v_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e04704-47f6-40ad-af44-cf7ce5b9cffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(21, 9.5))\n",
    "gs = fig.add_gridspec(2, 2)\n",
    "fontsize=16\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "# ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"v_pred_mean\")\n",
    "im = ax.imshow((torch.mean(v_samp, axis=0).cpu().detach().numpy())/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\")\n",
    "cbar.ax.set_title('km/s', size=fontsize)\n",
    "cbar.ax.tick_params(labelsize=fontsize)\n",
    "# 设置colorbar的取值范围\n",
    "vmin = ((vp_tensor[0])/1000).min()  # 最小值\n",
    "vmax = ((vp_tensor[0])/1000).max()  # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "ax.set_xlabel(\"Distance x[km]\", fontsize=fontsize)\n",
    "ax.set_title('v_pred_mean', fontsize=fontsize)\n",
    "ax.set_ylabel(\"Depth z[km]\",fontsize=fontsize)\n",
    "ax.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 1])\n",
    "# ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"v_pred_std\")\n",
    "im = ax.imshow((torch.std(v_samp, axis=0).cpu().detach().numpy())/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\")\n",
    "cbar.ax.set_title('km/s', size=fontsize)\n",
    "cbar.ax.tick_params(labelsize=fontsize)\n",
    "# 设置colorbar的取值范围\n",
    "vmin = ((torch.std(v_samp, axis=0))/1000).min()  # 最小值\n",
    "vmax = ((torch.std(v_samp, axis=0))/1000).max()  # 最大值\n",
    "# vmax = 0.2  # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "ax.set_xlabel(\"Distance x[km]\", fontsize=fontsize)\n",
    "ax.set_title('v_pred_std', fontsize=fontsize)\n",
    "ax.set_ylabel(\"Depth z[km]\",fontsize=fontsize)\n",
    "ax.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(gs[1, 0])\n",
    "# ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"vp_tensor\")\n",
    "im = ax.imshow((vp_tensor[0].cpu().detach().numpy())/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\")\n",
    "cbar.ax.set_title('km/s', size=fontsize)\n",
    "cbar.ax.tick_params(labelsize=fontsize)\n",
    "# 设置colorbar的取值范围\n",
    "vmin = ((vp_tensor[0])/1000).min()  # 最小值\n",
    "vmax = ((vp_tensor[0])/1000).max()  # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "ax.set_xlabel(\"Distance x[km]\", fontsize=fontsize)\n",
    "ax.set_title('vp', fontsize=fontsize)\n",
    "ax.set_ylabel(\"Depth z[km]\",fontsize=fontsize)\n",
    "ax.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(gs[1, 1])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"vp-v_pred_mean\")\n",
    "im = ax.imshow(np.abs((vp_tensor[0].cpu()-torch.mean(v_samp, axis=0).cpu()).detach().numpy())/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\")\n",
    "cbar.ax.set_title('km/s', size=fontsize)\n",
    "cbar.ax.tick_params(labelsize=fontsize)\n",
    "# cbar.set_label('km/s', size=fontsize)\n",
    "# 设置colorbar的取值范围\n",
    "vmin = 0\n",
    "vmax=((vp_tensor[0].cpu()-torch.mean(v_samp, axis=0)).cpu()).max()/1000\n",
    "im.set_clim(vmin, vmax)\n",
    "ax.set_xlabel(\"Distance x[km]\", fontsize=fontsize)\n",
    "ax.set_title('vp-v_pred_mean', fontsize=fontsize)\n",
    "ax.set_ylabel(\"Depth z[km]\",fontsize=fontsize)\n",
    "ax.tick_params(axis='both', which='major', labelsize=fontsize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571da7b3-3ca8-4b54-b74c-2c357d89a77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(v_samp, './Figures/v_samp/v_samp_add/v_samp_VAE_over_scale4Hz.pth')\n",
    "v_samp= torch.load('./Figures/v_samp/v_samp_add/v_samp_VAE_over_scale4Hz.pth').cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fea5fba-bd44-45fc-83f4-3795d1f869c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d2b994-5a0e-4b18-b50c-785775a04171",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
