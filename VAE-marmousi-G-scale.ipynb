{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c370f01b-6df5-4369-9190-a0ee19894040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.insert(1, './codes/codes')  # insert at 1, 0 is the script path (or '' in REPL)\n",
    "\n",
    "print(\"----------------\")\n",
    "!python --version\n",
    "!nvidia-smi\n",
    "print(\"----------------\")\n",
    "print(\"System Version: \", sys.version)\n",
    "\n",
    "## ======================================================== ##\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from plot_functions import add_colorbar, imagesc\n",
    "\n",
    "print(\"PyTorch Version: \", torch.__version__)\n",
    "print(\"----------------\")\n",
    "print(\"torch.cuda.is_available: \",torch.cuda.is_available())\n",
    "print(\"----------------\")\n",
    "print(torch.__version__, torch.version.cuda, torch.cuda.get_device_name(0))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# deterministic behavior\n",
    "torch.manual_seed(3)\n",
    "torch.cuda.manual_seed_all(3)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(3)\n",
    "# random.seed(3)\n",
    "os.environ['PYTHONHASHSEED'] = str(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aa9c0b-6311-4138-ab96-9cd006f6eb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6c9137-621e-4223-852b-bde04cf5a45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "def zip_dir(dirpath, outFullName):\n",
    "    zip = zipfile.ZipFile(outFullName, 'w', zipfile.ZIP_DEFLATED)\n",
    "    for root, dirs, files in os.walk(dirpath):\n",
    "        for file in files:\n",
    "            zip.write(os.path.join(root, file))\n",
    "    zip.close()\n",
    "\n",
    "def unzip(zip_filepath, dest_path):\n",
    "    with zipfile.ZipFile(zip_filepath, 'r') as zip_ref:\n",
    "        zip_ref.extractall(dest_path)\n",
    "        \n",
    "# zip_dir('./codes', './codes.zip')        \n",
    "unzip('./codes.zip', './codes2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3bc678-64c0-4e9e-ba04-aeaf08bafa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "# Load the velocity model \n",
    "vmodel = np.array(pd.read_csv(\"./vel_marmousi_376x1151.csv\")) \n",
    "# v_init = np.array(pd.read_csv(\"./vel_marmousi_smooth400_376x1151.csv\"))\n",
    "v_init = np.array(pd.read_csv(\"./vel_marmousi_376x1151.csv\"))\n",
    "# v_init = gaussian_filter(v_init, sigma=10)\n",
    "v_init = gaussian_filter(v_init, sigma=15)\n",
    "\n",
    "dz = 8\n",
    "nz, nx = vmodel.shape\n",
    "print(\"Original Model Shape: {}, Grid Interval: {}m\".format(vmodel.shape, dz))\n",
    "\n",
    "################# Plot true & initial velocity model #################\n",
    "fig = plt.figure(figsize=(12, 2))\n",
    "gs = fig.add_gridspec(1, 2)\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\")\n",
    "im = ax.imshow(vmodel/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 1])\n",
    "ax.set( xlabel=\"Distance x[km]\")\n",
    "im = ax.imshow(v_init/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "################# Plot true & initial velocity model #################\n",
    "\n",
    "\n",
    "dz = 32\n",
    "vp_tensor_init = torch.from_numpy(vmodel).type(dtype=torch.float32).to(device)\n",
    "vi_tensor_init = torch.from_numpy(v_init).type(dtype=torch.float32).to(device)\n",
    "sea = (torch.ones([9,1151])*1500).type(dtype=torch.float32).to(device)\n",
    "vp_tensor = torch.cat([sea, vp_tensor_init], axis=0)[None, ::4, 70:1094:4]\n",
    "vi_tensor_init = torch.from_numpy(gaussian_filter(vp_tensor_init.cpu().numpy(), sigma=30)).type(dtype=torch.float32).to(device)\n",
    "vi_tensor = torch.cat([sea, vi_tensor_init], axis=0)[None, ::4, 70:1094:4]\n",
    "\n",
    "nv, nz, nx = vp_tensor.shape\n",
    "print(\"Resampled Model Shape: {}, Grid Interval: {}m\".format((nz, nx), dz))\n",
    "\n",
    "# Setting locations of sources and receivers\n",
    "xs = torch.arange(10, nx-10, 12, dtype=torch.long).repeat([nv, 1])      # x-coordinate for sources\n",
    "ns = xs.shape[1]                                                        # number of shots \n",
    "xr = torch.arange(0, nx, 1, dtype=torch.long).repeat([nv, ns, 1])       # x-coordinate for receivers\n",
    "zs = torch.full((nv, ns), 0, dtype=torch.long)                          # depth of sources    震源深度\n",
    "zr = torch.full((nv, ns, nx), 0, dtype=torch.long)                      # depth of receivers 地表\n",
    "print(\"Number of shots: {}, with interval: {}m, in depth: {}m\".format(ns, (xs[0, 1]-xs[0, 0])*dz, zs[0, 0]*dz))\n",
    "print(xs)\n",
    "\n",
    "################# Plot true & initial velocity model #################\n",
    "fig = plt.figure(figsize=(12, 2))\n",
    "gs = fig.add_gridspec(1, 2)\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\")\n",
    "im = ax.imshow(vp_tensor[0].cpu().numpy()/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 1])\n",
    "ax.set( xlabel=\"Distance x[km]\")\n",
    "im = ax.imshow(vi_tensor[0].cpu().numpy()/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "# ################# Plot true & initial velocity model #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee323def-f620-4314-a3fb-72b886ad4e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vi_tensor, './Figures/v_samp/vi_tensor_scale.pth')\n",
    "torch.save(vp_tensor, './Figures/v_samp/vp_tensor_scale.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d4d7ae-2493-4bc9-a8e1-89c2f221e354",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rnn_fd import rnn2D\n",
    "from generator_old import wGenerator #单频雷克子波\n",
    "\n",
    "freeSurface = True                                                      # free surface option for forward modeling\n",
    "npad = 15                                                               # velocity padding in grid points\n",
    "freq = 4                                                               # dominant frequency of wavelet in Hz\n",
    "dt = 0.003                                                            # time samling interval, fixed for all shots gathers\n",
    "nt = 2048                                                             # number of samples in time\n",
    "t = dt * torch.arange(0, nt, dtype=torch.float32)                       # create time vector\n",
    "wavelet = wGenerator(t, freq).ricker().to(device)                       # generate wavelet\n",
    "nx_pad = nx + 2 * npad\n",
    "nz_pad = nz + npad if freeSurface else nz + 2 * npad\n",
    "f = np.arange(0, nt/2+1) / (nt*dt)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 2.5))\n",
    "gs = fig.add_gridspec(1, 2)\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "ax.set(xlabel=\"$Time$\", ylabel=\"$Amp$\", title=\"$Ricker$\", xlim=[0, 1])\n",
    "ax.plot(t, wavelet.cpu().numpy(), color='red', linestyle='-', linewidth=1.5)\n",
    "ax.grid(True, which='both', linestyle='--', color='grey', linewidth=.8, alpha=1.0)\n",
    "ax.minorticks_on()\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 1])\n",
    "ax.set(xlabel=\"$Frequency [Hz]$\", ylabel=\"$Amp$\", title=\"$Amp Spectrum$\", xlim=[0, 40])\n",
    "ax.plot(f, np.abs(torch.fft.rfft(wavelet).cpu().numpy()), color='red', linestyle='-', linewidth=1.5)\n",
    "ax.grid(True, which='both', linestyle='--', color='grey', linewidth=.8, alpha=1.0)\n",
    "ax.minorticks_on()\n",
    "\n",
    "################## Check the stability condition #################\n",
    "print(vp_tensor.max()*dt/dz/np.sqrt(1/2),\"< 1\") # should <1\n",
    "print(vp_tensor.min()/10/freq/dz,\"> 1\") # should >1\n",
    "\n",
    "forward_rnn = rnn2D(nz, nx, zs, xs, zr, xr, dz, dt, \n",
    "                    npad=npad, order=2, vmax=vp_tensor.max(), \n",
    "                    log_para=1e-6,\n",
    "                    freeSurface=True, \n",
    "                    dtype=torch.float32, \n",
    "                    device=device).to(device)\n",
    "\n",
    "# # forward modeling\n",
    "# _, _, shots, _ = forward_rnn(vmodel=vp_tensor.to(device), segment_wavelet=wavelet)\n",
    "# _, _, shots_init, _ = forward_rnn(vmodel=vi_tensor.to(device), segment_wavelet=wavelet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3fda76-bf94-4c4f-870f-34d5ad3417b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(shots, \"./shots_marmousi_I_scale2048_shots20.npz\")\n",
    "shots = torch.load(\"./shots_marmousi_I_scale2048_shots20.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762b4bea-3817-4a29-8170-f35976ddbc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(ns*1.5, 8))\n",
    "imagesc(fig,\n",
    "        shots.cpu().numpy().reshape(-1, ns, nt, nx),\n",
    "        vmin=-shots.max()/30,\n",
    "        vmax=shots.max()/30,\n",
    "        extent=[0, nx*dz/1000, t.numpy().max(), 0],\n",
    "        aspect=6,\n",
    "        nRows_nCols=(1, ns),\n",
    "        cmap='RdBu_r', #seismic\n",
    "        ylabel=\"Time[s]\",\n",
    "        xlabel=\"Position[km]\",\n",
    "        clabel=\"\",\n",
    "        xticks=np.arange(0., int(nx*dz/1000), 2),\n",
    "        yticks=np.arange(0., t.numpy().max(), .5),\n",
    "        fontsize=15,\n",
    "        cbar_width=\"7%\",\n",
    "        cbar_height=\"100%\",\n",
    "        cbar_loc='lower left')\n",
    "fig.tight_layout(pad=-0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19e187e-46b6-4831-911d-b09743dac60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(ns*1.5, 8))\n",
    "imagesc(fig,\n",
    "        shots.cpu().numpy().reshape(-1, ns, nt, nx),\n",
    "        vmin=-shots.max()/30,\n",
    "        vmax=shots.max()/30,\n",
    "        extent=[0, nx*dz/1000, t.numpy().max(), 0],\n",
    "        aspect=4,\n",
    "        nRows_nCols=(1, 6),\n",
    "        cmap='RdBu_r', #seismic\n",
    "        ylabel=\"Time[s]\",\n",
    "        xlabel=\"Position[km]\",\n",
    "        clabel=\"\",\n",
    "        xticks=np.arange(0., int(nx*dz/1000), 2),\n",
    "        yticks=np.arange(0., t.numpy().max(), .5),\n",
    "        fontsize=15,\n",
    "        cbar_width=\"7%\",\n",
    "        cbar_height=\"100%\",\n",
    "        cbar_loc='lower left')\n",
    "fig.tight_layout(pad=-0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f92305-2a18-4f1e-81b4-410afba88212",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VAE\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, k_size=3, stride=1, padding=1):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(nn.Conv2d(in_channels, \n",
    "                                             out_channels, \n",
    "                                             kernel_size=k_size, \n",
    "                                             stride=stride, \n",
    "                                             padding=padding),\n",
    "                                   nn.BatchNorm2d(out_channels),\n",
    "                                   nn.LeakyReLU()\n",
    "                                  )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class TransConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, k_size=3, stride=2, padding=1):\n",
    "        super(TransConvBlock, self).__init__()\n",
    "        \n",
    "        self.transconv = nn.Sequential(nn.ConvTranspose2d(in_channels, \n",
    "                                                          out_channels, \n",
    "                                                          kernel_size=k_size, \n",
    "                                                          stride=stride, \n",
    "                                                          padding=padding),\n",
    "                                       nn.BatchNorm2d(out_channels),\n",
    "                                       nn.LeakyReLU()\n",
    "                                       )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.transconv(x)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class TransConvBlock_last(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, k_size=3, stride=2, padding=1):\n",
    "        super(TransConvBlock_last, self).__init__()\n",
    "        \n",
    "        self.transconv = nn.Sequential(nn.ConvTranspose2d(in_channels, \n",
    "                                                          out_channels, \n",
    "                                                          kernel_size=k_size, \n",
    "                                                          stride=stride, \n",
    "                                                          padding=padding),\n",
    "                                       nn.BatchNorm2d(out_channels)\n",
    "                                       )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.transconv(x)\n",
    "        return out\n",
    "        \n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, latent_dim=256):\n",
    "        super(MyModel, self).__init__()    \n",
    "        \n",
    "        #encoder--------------------------------------------                                  \n",
    "        self.conv_block_1 = ConvBlock(20, 32, k_size=(4,1), stride=(2,1), padding=(1,0))      \n",
    "        self.conv_block_2 = ConvBlock(32, 64, k_size=(4,1), stride=(2,1), padding=(1,0)) \n",
    "        self.conv_block_22 = ConvBlock(64, 64, k_size=(4,1), stride=(2,1), padding=(1,0)) \n",
    "        self.conv_block_3 = ConvBlock(64, 128, k_size=4, stride=2, padding=1)          \n",
    "        self.conv_block_4 = ConvBlock(128, 256, k_size=3, stride=2, padding=1)         \n",
    "        self.conv_block_5 = ConvBlock(256, 512, k_size=3, stride=2, padding=1)      \n",
    "        self.conv_block_6 = ConvBlock(512, 512, k_size=3, stride=2, padding=1)   \n",
    "        \n",
    "        #decoder--------------------------------------------     \n",
    "        self.trans_conv_block_1 = TransConvBlock(512, 256, k_size=(1,4), stride=(1,2), padding=(0,1))                \n",
    "        self.trans_conv_block_2 = TransConvBlock(256, 128, k_size=4, stride=2, padding=1)                \n",
    "        self.trans_conv_block_3 = TransConvBlock(128, 64, k_size=(7,4), stride=(3,2), padding=(2,1))                \n",
    "        self.trans_conv_block_4 = TransConvBlock(64, 32, k_size=(3,4), stride=(1,2), padding=(1,1))                      \n",
    "        self.trans_conv_block_5 = TransConvBlock_last(32, 1, k_size=3, stride=1, padding=1)                \n",
    "\n",
    "        self.fc_mu = nn.Linear(16*16*512, latent_dim)\n",
    "        self.fc_var = nn.Linear(16*16*512, latent_dim)\n",
    "        self.decoder_input = nn.Linear(latent_dim, 16*16*512)\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.conv_block_2(x)\n",
    "        x = self.conv_block_22(x)\n",
    "        x = self.conv_block_3(x)\n",
    "        x = self.conv_block_4(x)\n",
    "        x = self.conv_block_5(x)    \n",
    "        result = self.conv_block_6(x)    \n",
    "        result = torch.flatten(result, start_dim=1)\n",
    "        mu = self.fc_mu(result)\n",
    "        log_var = self.fc_var(result)\n",
    "\n",
    "        return mu, log_var\n",
    "\n",
    "        \n",
    "    def decode(self, x):\n",
    "        x = self.decoder_input(x)\n",
    "        x_view = x.view(1, 512, 16, 16)\n",
    "        self.x_view = x_view.detach() # 保存x_view为一个模型的属性\n",
    "        x = self.trans_conv_block_1(x_view)\n",
    "        x = self.trans_conv_block_2(x)\n",
    "        x = self.trans_conv_block_3(x)\n",
    "        x = self.trans_conv_block_4(x)\n",
    "        x = self.trans_conv_block_5(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        \"\"\"\n",
    "        Reparameterization trick to sample from N(mu, var) from\n",
    "        N(0,1).\n",
    "        :param mu: (Tensor) Mean of the latent Gaussian [B x D]\n",
    "        :param logvar: (Tensor) Standard deviation of the latent Gaussian [B x D]\n",
    "        :return: (Tensor) [B x D]\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps * std + mu\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        v_pred = self.decode(z)  \n",
    "      \n",
    "        return v_pred, mu, log_var\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616a533f-8d06-4118-9e52-fcf6db2a7d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "model = MyModel()\n",
    "inputs = (1, 24, 2048, 256)\n",
    "summary(model, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ac1d1f-6012-42e1-81e0-16cb5eca2858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchinfo\n",
    "print(torchinfo.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca851c7f-5fda-403b-84ee-134d2fb08d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_tensor_norm = (vp_tensor - 2900)/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566971b4-dc44-40d4-be25-c233a6c68cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint-FWI-pre-marmousi_I-9-1000\n",
    "\n",
    "fig = plt.figure(figsize=(20, 7))\n",
    "gs = fig.add_gridspec(2, 2)\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"vp_tensor\")\n",
    "im = ax.imshow((vp_tensor[0].cpu().detach().numpy())/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "# 设置colorbar的取值范围\n",
    "vmin = (vp_tensor[0]/1000).min() # 最小值\n",
    "vmax = ((vp_tensor[0])/1000).max()   # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 1])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"vp_tensor_norm\")\n",
    "im = ax.imshow((vp_tensor_norm[0].cpu().detach().numpy()), extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "# 设置colorbar的取值范围\n",
    "vmin = (vp_tensor_norm[0]).min() # 最小值\n",
    "vmax = (vp_tensor_norm[0]).max() # 最大值\n",
    "im.set_clim(vmin, vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d12fd8-034b-4bb6-81ac-5190ba011d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "# torchvision.models.vgg16().features\n",
    "\n",
    "def train(model_Jin, data, wavelet, vi_tensor, optimizer, device='cpu'):\n",
    "    \n",
    "    data_resample = data[:, :, :, :] \n",
    "    data_norm = (data_resample-data.mean())/(data.std()).to(device)\n",
    "   \n",
    "    train_loss = 0\n",
    "    data_norm = data_norm.to(device)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    v_recon_norm, mu, logvar = model_Jin(data_norm) \n",
    "   \n",
    "    v_recon = (v_recon_norm)*(1000) + 2900  \n",
    "    v_recon = v_recon.to(device).type(dtype=torch.float32)\n",
    "\n",
    "    loss_fn2 = nn.MSELoss()\n",
    "    Loss2 = loss_fn2(v_recon[0], vi_tensor)\n",
    "    loss = Loss2\n",
    "    \n",
    "    train_loss += loss.detach().cpu().item()\n",
    "    loss.backward()\n",
    "   \n",
    "    optimizer.step()\n",
    "    \n",
    "    return [train_loss], v_recon[0], data\n",
    "\n",
    "def save_state(epoch, model, optimizer, train_loss_history):\n",
    "    import os\n",
    "    state = {'epoch': epoch + 1,\n",
    "             'train_loss_history': train_loss_history,\n",
    "             'state_dict': model.state_dict(),\n",
    "             'optimizer': optimizer.state_dict()\n",
    "             }\n",
    "    torch.save(state, \"./checkpoints-VAE-marmousi-G-scale/checkpoint-VAE-pre-marmousi-2-{}.pth\".format(epoch+1))\n",
    "    if os.path.exists(\"./checkpoints-VAE-marmousi-G-scale/checkpoint-VAE-pre-marmousi-2-{}.pth\".format(epoch)):\n",
    "        os.remove(\"./checkpoints-VAE-marmousi-G-scale/checkpoint-VAE-pre-marmousi-2-{}.pth\".format(epoch))\n",
    "\n",
    "def load_state(model, optimizer, resume_file):\n",
    "    checkpoint = torch.load(resume_file)\n",
    "    resume_epoch = checkpoint['epoch']\n",
    "    train_loss_history = checkpoint['train_loss_history']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    return resume_epoch, model, optimizer, train_loss_history   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd001ae-8573-4c9e-bb6b-0bcd3b5c0b38",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "# 训练模型\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "data = torch.load(\"./shots_marmousi_I_scale2048_shots20.npz\", weights_only=True).to(device).type(dtype=torch.float32)  \n",
    "\n",
    "model = MyModel().to(device)\n",
    "optimizer = torch.optim.Adam([{'params': model.parameters()}], \n",
    "                               lr=0.0001, weight_decay=0.0001)\n",
    "\n",
    "max_epoch = 1000\n",
    "train_loss_history = []\n",
    "print_interval = 1\n",
    "for epoch in range(0, max_epoch):\n",
    "   \n",
    "    train_loss, v_pred, s_pred  = train(model, data, wavelet, vi_tensor, optimizer, device)\n",
    "    train_loss_history.append(train_loss)\n",
    "    save_state(epoch, model, optimizer, train_loss_history)\n",
    "   \n",
    "    if (epoch + 1) % print_interval == 0: \n",
    "        print(\"Epoch: {}, Training Loss: {:.8f}\".format(epoch, train_loss[0]))\n",
    "\n",
    "train_loss_history = torch.tensor(train_loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e80ad1-4d27-4455-a21c-d23620f77cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 7))\n",
    "gs = fig.add_gridspec(2, 2)\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"v_pred_full\")\n",
    "im = ax.imshow((v_pred[0].cpu().detach().numpy())/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "# 设置colorbar的取值范围\n",
    "vmin = (vi_tensor[0]/1000).min() # 最小值\n",
    "vmax = ((vi_tensor[0])/1000).max()   # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(gs[1, 0])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"vi\")\n",
    "im = ax.imshow(((vi_tensor[0]).cpu().detach().numpy() )/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(gs[1, 1])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"loss\")\n",
    "im = ax.imshow(((v_pred[0]-vi_tensor[0]).cpu().detach().numpy() )/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "# 设置colorbar的取值范围\n",
    "vmin = -((v_pred[0]-vi_tensor[0])/1000).max()  # 最小值\n",
    "vmax = ((v_pred[0]-vi_tensor[0])/1000).max()   # 最大值\n",
    "im.set_clim(vmin, vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0196ef-e1d8-4337-98a6-ef0e6cd1ddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, wavelet, vp_tensor, optimizer, device='cpu'):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    \n",
    "    lamda1 = lamda2 = lamda3 = lamda4 = 1\n",
    "    \n",
    "    data_resample = data[:, :, :, :]   \n",
    "    data_norm = (data_resample-data.mean())/(data.std()).to(device)\n",
    "    \n",
    "    train_loss = 0\n",
    "    Loss_val = 0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    v_recon_norm, mu, logvar= model(data_norm)  \n",
    "    v_recon = (v_recon_norm)*(1000) + 2900  \n",
    "    _, _, shots, _ = forward_rnn(vmodel = v_recon[0].to(device), segment_wavelet=wavelet)\n",
    "    shots_resample = shots[:, :, :, :]\n",
    "    \n",
    "    data_rgb = data_resample[0][:,None,].repeat(1, 3, 1, 1)     \n",
    "    shots_rgb = shots_resample[0][:,None,].repeat(1, 3, 1, 1)  \n",
    "    data_rgb_norm = (data_rgb-data_rgb.mean())/(data_rgb.std()) \n",
    "    shots_rgb_norm = (shots_rgb-data_rgb.mean())/(data_rgb.std())\n",
    "    data_vgg = model_vgg(data_rgb_norm)\n",
    "    shots_vgg = model_vgg(shots_rgb_norm)\n",
    "   \n",
    "    loss_fn1 = nn.L1Loss()\n",
    "    loss_fn2 = nn.MSELoss()\n",
    "   \n",
    "    Loss1 = loss_fn1(data_resample, shots_resample)\n",
    "    Loss2 = loss_fn2(data_resample, shots_resample)\n",
    "    L_recon_pixel = lamda1*Loss1 + lamda2*Loss2\n",
    "    \n",
    "    Loss3 = loss_fn1(data_vgg, shots_vgg)\n",
    "    Loss4 = loss_fn2(data_vgg, shots_vgg)\n",
    "    L_recon_perceptual = lamda3*Loss3 + lamda4*Loss4\n",
    "    \n",
    "    KLD = -0.5 * torch.sum(1 + torch.log((torch.exp(0.5 * logvar)).pow(2)) - mu.pow(2) - (torch.exp(0.5 * logvar)).pow(2))  #先验 N(0,1)\n",
    "   \n",
    "    loss = L_recon_pixel + L_recon_perceptual + KLD  \n",
    "    \n",
    "    train_loss += loss.detach().cpu().item()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    loss_fn2 = nn.MSELoss()\n",
    "    Loss_val = loss_fn2(v_recon[0], vp_tensor)\n",
    "    Loss_val += Loss_val.detach().cpu().item()\n",
    "    return [train_loss, L_recon_pixel, L_recon_perceptual, KLD, Loss_val], v_recon[0], shots, mu, logvar \n",
    "    \n",
    "\n",
    "def test(model, data, device='cpu'):\n",
    "    model.eval()\n",
    "    data_resample = data[:, :, :, :] \n",
    "    data_norm = (data_resample-data.mean())/(data.std()).to(device)\n",
    "    \n",
    "    v_recon_norm, mu, logvar= model(data_norm)  \n",
    "    v_recon = (v_recon_norm)*(1000) + 2900  \n",
    "   \n",
    "    return v_recon[0], mu, logvar \n",
    "\n",
    "\n",
    "def save_state(epoch, model, optimizer, train_loss_history):\n",
    "    import os\n",
    "    state = {'epoch': epoch + 1,\n",
    "             'train_loss_history': train_loss_history,\n",
    "             'state_dict': model.state_dict(),\n",
    "             'optimizer': optimizer.state_dict()\n",
    "             }\n",
    "    torch.save(state, \"./checkpoints-VAE-marmousi-G-scale/checkpoint-VAE-marmousi-2-{}.pth\".format(epoch+1)) \n",
    "    \n",
    "\n",
    "        \n",
    "def load_state(model, optimizer, resume_file):\n",
    "    checkpoint = torch.load(resume_file)\n",
    "    resume_epoch = checkpoint['epoch']\n",
    "    train_loss_history = checkpoint['train_loss_history']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    return resume_epoch, model, optimizer, train_loss_history   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fba227-647a-449d-b640-c5124cf8849c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision\n",
    "\n",
    "# 训练模型\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "data = torch.load(\"./shots_marmousi_I_scale2048_shots20.npz\").to(device).type(dtype=torch.float32) \n",
    "\n",
    "model = MyModel().to(device)\n",
    "optimizer = torch.optim.Adam([{'params': model.parameters()}], \n",
    "                               lr=0.0001, weight_decay=0.0001)\n",
    "_, model, _, _ = load_state(model, optimizer, \"./checkpoints-VAE-marmousi-G-scale/checkpoint-VAE-pre-marmousi-2-1000.pth\") \n",
    "optimizer = torch.optim.AdamW([{'params': model.parameters()}], \n",
    "                               lr=0.00001, betas=(0.9, 0.999), weight_decay=0.0001)\n",
    "model_vgg = torchvision.models.vgg16(pretrained=True).features[:13].to(device) #第13层输出--conv5的结果。\n",
    "\n",
    "max_epoch = 3000    \n",
    "train_loss_history = [[], [], [], [], []] \n",
    "print_interval = 1\n",
    "\n",
    "for epoch in range(0, max_epoch):\n",
    "\n",
    "    train_loss, v_pred, s_pred, mu, logvar = train(model, data, wavelet, vp_tensor, optimizer, device)\n",
    "    for i in range(5):  \n",
    "        train_loss_history[i].append(train_loss[i]) \n",
    "    \n",
    "    if epoch == 0 or (epoch < 100 and (epoch + 1) % 10 == 0) or (epoch >= 100 and (epoch + 1) % 100 == 0):\n",
    "        save_state(epoch, model, optimizer, train_loss_history)\n",
    "     \n",
    "    if (epoch + 1) % print_interval == 0:\n",
    "        print(\"Epoch: {}, Training Loss: {:.8f}, recon_pixel Loss: {:.8f}, recon_perceptual Loss: {:.8f}, KLD Loss: {:.8f}, recon_vmodel Loss: {:.8f}\".format(epoch, train_loss[0], train_loss[1], train_loss[2], train_loss[3], train_loss[4]))\n",
    "\n",
    "train_loss_history = torch.tensor(train_loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f64528-b0bc-480e-bd75-7360a509d49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_history = torch.tensor(train_loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e780c7-e9cc-46a9-bc24-7ced27a4079a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n=3000\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.plot(np.arange(0,n), train_loss_history[0, 0:n].numpy(), label=\"all\")\n",
    "plt.plot(np.arange(0,n), train_loss_history[1, 0:n].numpy(), label=\"recon_pixel\")\n",
    "plt.plot(np.arange(0,n), train_loss_history[2, 0:n].numpy(), label=\"recon_percep\")\n",
    "plt.plot(np.arange(50,n), train_loss_history[3, 50:n].numpy(), label=\"KLD\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e718d8-55f0-4961-98e4-669fe417759c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.plot(np.arange(0,n), train_loss_history[4, 0:n].numpy(), label=\"recon_vp\")\n",
    "\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096f268e-486c-4839-bbb8-2d0d4881dc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 15))\n",
    "gs = fig.add_gridspec(3, 2)\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"v_pred\")\n",
    "im = ax.imshow((v_pred[0].cpu().detach().numpy())/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "# 设置colorbar的取值范围\n",
    "vmin = ((vp_tensor[0])/1000).min()  # 最小值\n",
    "vmax = ((vp_tensor[0])/1000).max()  # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "\n",
    "ax = fig.add_subplot(gs[1, 1])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"vp\")\n",
    "im = ax.imshow(((vp_tensor[0]).cpu().detach().numpy() )/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "# 设置colorbar的取值范围\n",
    "vmin = ((vp_tensor[0])/1000).min()  # 最小值\n",
    "vmax = ((vp_tensor[0])/1000).max()  # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "\n",
    "ax = fig.add_subplot(gs[1, 0])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"vi\")\n",
    "im = ax.imshow(((vi_tensor[0]).cpu().detach().numpy() )/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "vmin = ((vp_tensor[0])/1000).min()  # 最小值\n",
    "vmax = ((vp_tensor[0])/1000).max()  # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "\n",
    "ax = fig.add_subplot(gs[2, 1])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"v_pred-vp\")\n",
    "im = ax.imshow(((v_pred[0]-vp_tensor[0]).cpu().detach().numpy() )/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "# 设置colorbar的取值范围\n",
    "vmin = -((v_pred[0]-vp_tensor[0])/1000).max()  # 最小值\n",
    "vmax = ((v_pred[0]-vp_tensor[0])/1000).max()   # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(gs[2, 0])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"v_pred-vi\")\n",
    "im = ax.imshow(((v_pred[0]-vi_tensor[0]).cpu().detach().numpy() )/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "# 设置colorbar的取值范围\n",
    "vmin = -((v_pred[0]-vi_tensor[0])/1000).max()   # 最小值\n",
    "vmax = ((v_pred[0]-vi_tensor[0])/1000).max()   # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81e4fa5-298f-496e-b739-8aef348a4232",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision\n",
    "\n",
    "# 训练模型\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "data = torch.load(\"./shots_marmousi_I_scale2048_shots20.npz\").to(device).type(dtype=torch.float32)  \n",
    "\n",
    "model = MyModel().to(device)\n",
    "optimizer = torch.optim.AdamW([{'params': model.parameters()}], \n",
    "                               lr=0.00001, betas=(0.9, 0.999), weight_decay=0.0001)\n",
    "\n",
    "_, model, _, train_loss_history = load_state(model, optimizer, \"./checkpoints-VAE-marmousi-G-scale/checkpoint-VAE-marmousi-2-3000.pth\") \n",
    "\n",
    "model_vgg = torchvision.models.vgg16(pretrained=True).features[:13].to(device) #第13层输出--conv5的结果。\n",
    "\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2bf590-4bf4-4820-8ebd-2cf2e6f06c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data, device='cpu'):\n",
    "    model.eval()\n",
    "    data_resample = data[:, :, :, :]  \n",
    "    data_norm = (data_resample-data.mean())/(data.std()).to(device)\n",
    "    with torch.no_grad():\n",
    "        v_recon_norm, mu, logvar= model(data_norm) \n",
    "        v_recon = (v_recon_norm)*(1000) + 2900  \n",
    "    return v_recon[0], mu, logvar \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440c8b72-9a63-4572-8f4f-fbffbccd22be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples = 500\n",
    "v_samp = torch.zeros((samples, 96, 256))\n",
    "for s in range(samples):\n",
    "    v_pred, _, _ = test(model, data, device)\n",
    "    v_samp[s] = v_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015e0f9e-08bc-4d99-8be1-c8cb29eb8be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_samp_a = v_samp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebe3deb-f046-4d87-875e-d3c3fc4b51c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(v_samp, './v_samp_eval_VAE_scale.pth')\n",
    "v_samp= torch.load('./Figures/v_samp/v_samp_eval_VAE_scale.pth').cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02d7e03-b070-4115-b031-80b955a3b937",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(21, 9.5))\n",
    "gs = fig.add_gridspec(2, 2)\n",
    "fontsize=16\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "# ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"v_pred_mean\")\n",
    "im = ax.imshow((torch.mean(v_samp, axis=0).cpu().detach().numpy())/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\")\n",
    "cbar.ax.set_title('km/s', size=fontsize)\n",
    "cbar.ax.tick_params(labelsize=fontsize)\n",
    "# 设置colorbar的取值范围\n",
    "vmin = ((vp_tensor[0])/1000).min()  # 最小值\n",
    "vmax = ((vp_tensor[0])/1000).max()  # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "ax.set_xlabel(\"Distance x[km]\", fontsize=fontsize)\n",
    "ax.set_title('v_pred_mean', fontsize=fontsize)\n",
    "ax.set_ylabel(\"Depth z[km]\",fontsize=fontsize)\n",
    "ax.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 1])\n",
    "# ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"v_pred_std\")\n",
    "im = ax.imshow((torch.std(v_samp/1000, axis=0).cpu().detach().numpy()), extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\")\n",
    "cbar.ax.set_title('km/s', size=fontsize)\n",
    "cbar.ax.tick_params(labelsize=fontsize)\n",
    "# 设置colorbar的取值范围\n",
    "vmin = ((torch.std(v_samp/1000, axis=0))).min()  # 最小值\n",
    "vmax = ((torch.std(v_samp/1000, axis=0))).max()  # 最大值\n",
    "# vmax = 0.2  # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "ax.set_xlabel(\"Distance x[km]\", fontsize=fontsize)\n",
    "ax.set_title('v_pred_std', fontsize=fontsize)\n",
    "ax.set_ylabel(\"Depth z[km]\",fontsize=fontsize)\n",
    "ax.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(gs[1, 0])\n",
    "# ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"vp_tensor\")\n",
    "im = ax.imshow((vp_tensor[0].cpu().detach().numpy())/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\")\n",
    "cbar.ax.set_title('km/s', size=fontsize)\n",
    "cbar.ax.tick_params(labelsize=fontsize)\n",
    "# 设置colorbar的取值范围\n",
    "vmin = ((vp_tensor[0])/1000).min()  # 最小值\n",
    "vmax = ((vp_tensor[0])/1000).max()  # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "ax.set_xlabel(\"Distance x[km]\", fontsize=fontsize)\n",
    "ax.set_title('vp', fontsize=fontsize)\n",
    "ax.set_ylabel(\"Depth z[km]\",fontsize=fontsize)\n",
    "ax.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(gs[1, 1])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"vp-v_pred_mean\")\n",
    "im = ax.imshow(np.abs((vp_tensor[0].cpu()-torch.mean(v_samp, axis=0).cpu()).detach().numpy())/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\")\n",
    "cbar.ax.set_title('km/s', size=fontsize)\n",
    "cbar.ax.tick_params(labelsize=fontsize)\n",
    "# cbar.set_label('km/s', size=fontsize)\n",
    "# 设置colorbar的取值范围\n",
    "vmin = 0\n",
    "vmax=((vp_tensor[0].cpu()-torch.mean(v_samp, axis=0)).cpu()).max()/3/1000\n",
    "im.set_clim(vmin, vmax)\n",
    "ax.set_xlabel(\"Distance x[km]\", fontsize=fontsize)\n",
    "ax.set_title('vp-v_pred_mean', fontsize=fontsize)\n",
    "ax.set_ylabel(\"Depth z[km]\",fontsize=fontsize)\n",
    "ax.tick_params(axis='both', which='major', labelsize=fontsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dde5365-09fd-4da1-b6d2-11fa5e4575be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0348652f-4e13-482f-95dd-fd49e70e7c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a5c833-8507-472e-b074-643070dadafd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
