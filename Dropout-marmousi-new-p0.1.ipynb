{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c370f01b-6df5-4369-9190-a0ee19894040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.insert(1, './codes')  # insert at 1, 0 is the script path (or '' in REPL)\n",
    "\n",
    "print(\"----------------\")\n",
    "!python --version\n",
    "!nvidia-smi\n",
    "print(\"----------------\")\n",
    "print(\"System Version: \", sys.version)\n",
    "\n",
    "## ======================================================== ##\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from plot_functions import add_colorbar, imagesc\n",
    "\n",
    "print(\"PyTorch Version: \", torch.__version__)\n",
    "print(\"----------------\")\n",
    "print(\"torch.cuda.is_available: \",torch.cuda.is_available())\n",
    "print(\"----------------\")\n",
    "print(torch.__version__, torch.version.cuda, torch.cuda.get_device_name(0))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# deterministic behavior\n",
    "torch.manual_seed(3)\n",
    "torch.cuda.manual_seed_all(3)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(3)\n",
    "# random.seed(3)\n",
    "os.environ['PYTHONHASHSEED'] = str(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01657fb2-edb1-4643-adfd-febe690e59f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deterministic behavior\n",
    "def seed_everything(seed):\n",
    "    import os\n",
    "    import torch\n",
    "    import random\n",
    "    import numpy as np\n",
    "    random.seed(seed)            # Python random module\n",
    "    np.random.seed(seed)         # Numpy Module\n",
    "    torch.manual_seed(seed)      # Current CPU\n",
    "    torch.cuda.manual_seed(seed) # Current GPU\n",
    "    torch.cuda.manual_seed_all(seed) # All GPU\n",
    "    torch.backends.cudnn.benchmark = False    # Close Optimization\n",
    "    torch.backends.cudnn.deterministic = True # Close Optimization\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "\n",
    "# 设置一个种子\n",
    "seed = 37\n",
    "# 调用函数以设置种子\n",
    "seed_everything(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3bc678-64c0-4e9e-ba04-aeaf08bafa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "# Load the velocity model \n",
    "vmodel = np.array(pd.read_csv(\"./vel_marmousi_376x1151.csv\")) \n",
    "v_init = np.array(pd.read_csv(\"./vel_marmousi_376x1151.csv\"))\n",
    "v_init = gaussian_filter(v_init, sigma=15)\n",
    "\n",
    "dz = 8\n",
    "nz, nx = vmodel.shape\n",
    "print(\"Original Model Shape: {}, Grid Interval: {}m\".format(vmodel.shape, dz))\n",
    "\n",
    "################# Plot true & initial velocity model #################\n",
    "fig = plt.figure(figsize=(12, 2))\n",
    "gs = fig.add_gridspec(1, 2)\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\")\n",
    "im = ax.imshow(vmodel/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 1])\n",
    "ax.set( xlabel=\"Distance x[km]\")\n",
    "im = ax.imshow(v_init/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "################# Plot true & initial velocity model #################\n",
    "\n",
    "\n",
    "dz = 15\n",
    "vp_tensor_init = torch.from_numpy(vmodel).type(dtype=torch.float32).to(device)\n",
    "vi_tensor_init = torch.from_numpy(v_init).type(dtype=torch.float32).to(device)\n",
    "sea = (torch.ones([9,1151])*5500).type(dtype=torch.float32).to(device)\n",
    "vp_tensor = torch.cat([vp_tensor_init, sea], axis=0)[None, ::3, 60:1084:4]\n",
    "vi_tensor = torch.cat([vp_tensor_init, sea], axis=0)[None, ::3, 60:1084:4]\n",
    "vi_tensor = torch.from_numpy(gaussian_filter(vi_tensor.cpu().numpy(), sigma=10)).type(dtype=torch.float32).to(device)\n",
    "\n",
    "nv, nz, nx = vp_tensor.shape\n",
    "print(\"Resampled Model Shape: {}, Grid Interval: {}m\".format((nz, nx), dz))\n",
    "\n",
    "# Setting locations of sources and receivers\n",
    "xs = torch.arange(20, nx-10, 20, dtype=torch.long).repeat([nv, 1])      # x-coordinate for sources\n",
    "ns = xs.shape[1]                                                        # number of shots \n",
    "xr = torch.arange(0, nx, 1, dtype=torch.long).repeat([nv, ns, 1])       # x-coordinate for receivers\n",
    "zs = torch.full((nv, ns), 0, dtype=torch.long)                          # depth of sources    震源深度\n",
    "zr = torch.full((nv, ns, nx), 0, dtype=torch.long)                      # depth of receivers 地表\n",
    "print(\"Number of shots: {}, with interval: {}m, in depth: {}m\".format(ns, (xs[0, 1]-xs[0, 0])*dz, zs[0, 0]*dz))\n",
    "print(xs)\n",
    "\n",
    "################# Plot true & initial velocity model #################\n",
    "fig = plt.figure(figsize=(12, 2))\n",
    "gs = fig.add_gridspec(1, 2)\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\")\n",
    "im = ax.imshow(vp_tensor[0].cpu().numpy()/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=0.8, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 1])\n",
    "ax.set( xlabel=\"Distance x[km]\")\n",
    "im = ax.imshow(vi_tensor[0].cpu().numpy()/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=0.8, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "# ################# Plot true & initial velocity model #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a8c50c-734b-4750-aa0d-8e01f39630bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_tensor.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23254da7-d922-4e5b-b20f-9fae5e13f9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_tensor.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d4d7ae-2493-4bc9-a8e1-89c2f221e354",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rnn_fd import rnn2D\n",
    "from generator_old import wGenerator #单频雷克子波\n",
    "\n",
    "freeSurface = True                                                      # free surface option for forward modeling\n",
    "npad = 15                                                               # velocity padding in grid points\n",
    "freq = 8                                                               # dominant frequency of wavelet in Hz\n",
    "dt = 0.0019                                                            # time samling interval, fixed for all shots gathers\n",
    "nt = 1024                                                              # number of samples in time\n",
    "t = dt * torch.arange(0, nt, dtype=torch.float32)                       # create time vector\n",
    "wavelet = wGenerator(t, freq).ricker().to(device)                       # generate wavelet\n",
    "nx_pad = nx + 2 * npad\n",
    "nz_pad = nz + npad if freeSurface else nz + 2 * npad\n",
    "f = np.arange(0, nt/2+1) / (nt*dt)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 2.5))\n",
    "gs = fig.add_gridspec(1, 2)\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "ax.set(xlabel=\"$Time$\", ylabel=\"$Amp$\", title=\"$Ricker$\", xlim=[0, 1])\n",
    "ax.plot(t, wavelet.cpu().numpy(), color='red', linestyle='-', linewidth=1.5)\n",
    "ax.grid(True, which='both', linestyle='--', color='grey', linewidth=.8, alpha=1.0)\n",
    "ax.minorticks_on()\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 1])\n",
    "ax.set(xlabel=\"$Frequency [Hz]$\", ylabel=\"$Amp$\", title=\"$Amp Spectrum$\", xlim=[0, 40])\n",
    "ax.plot(f, np.abs(torch.fft.rfft(wavelet).cpu().numpy()), color='red', linestyle='-', linewidth=1.5)\n",
    "ax.grid(True, which='both', linestyle='--', color='grey', linewidth=.8, alpha=1.0)\n",
    "ax.minorticks_on()\n",
    "\n",
    "################## Check the stability condition #################\n",
    "print(vp_tensor.max()*dt/dz/np.sqrt(1/2),\"< 1\") # should <1\n",
    "print(vp_tensor.min()/10/freq/dz,\"> 1\") # should >1\n",
    "\n",
    "forward_rnn = rnn2D(nz, nx, zs, xs, zr, xr, dz, dt, \n",
    "                    npad=npad, order=2, vmax=vp_tensor.max(), \n",
    "                    log_para=1e-6,\n",
    "                    freeSurface=True, \n",
    "                    dtype=torch.float32, \n",
    "                    device=device).to(device)\n",
    "\n",
    "# # forward modeling\n",
    "# _, _, shots, _ = forward_rnn(vmodel=vp_tensor.to(device), segment_wavelet=wavelet)\n",
    "# _, _, shots_init, _ = forward_rnn(vmodel=vi_tensor.to(device), segment_wavelet=wavelet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2861146a-830d-47b7-a403-266f6bee134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(shots, \"./shots_marmousi_I_2048.npz\")\n",
    "shots = torch.load(\"./shots_marmousi_I_2048.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f12c0c4-b874-4119-bef0-702f28290898",
   "metadata": {},
   "outputs": [],
   "source": [
    "shots.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6349ec11-a405-495f-8380-27414eff3378",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(ns*1.5, 8))\n",
    "imagesc(fig,\n",
    "        shots.cpu().numpy().reshape(-1, ns, nt, nx),\n",
    "        vmin=-shots.max()/30,\n",
    "        vmax=shots.max()/30,\n",
    "        extent=[0, nx*dz/1000, t.numpy().max(), 0],\n",
    "        aspect=6,\n",
    "        nRows_nCols=(1, ns),\n",
    "        cmap='RdBu_r', #seismic\n",
    "        ylabel=\"Time (s)\",\n",
    "        xlabel=\"Position (km)\",\n",
    "        clabel=\"\",\n",
    "        xticks=np.arange(0., int(nx*dz/1000), 2),\n",
    "        yticks=np.arange(0., t.numpy().max(), .5),\n",
    "        fontsize=8,\n",
    "        cbar_width=\"7%\",\n",
    "        cbar_height=\"100%\",\n",
    "        cbar_loc='lower left')\n",
    "fig.tight_layout(pad=-0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0003ddf9-b877-4b35-a5c7-70444168f4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, k_size=3, stride=1, padding=1):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(nn.Conv2d(in_channels, \n",
    "                                             out_channels, \n",
    "                                             kernel_size=k_size, \n",
    "                                             stride=1, # 将stride设置为1\n",
    "                                             padding=padding),\n",
    "                                   nn.MaxPool2d(kernel_size=stride),  # 添加MaxPool2d层，参数为原来的stride\n",
    "                                   nn.Dropout(p=0.1, inplace=False), \n",
    "                                   nn.BatchNorm2d(out_channels, track_running_stats=False),\n",
    "                                   nn.LeakyReLU()\n",
    "                                  )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        return out    \n",
    "    \n",
    "    \n",
    "class TransConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, k_size=3, stride=1, padding=1):\n",
    "        super(TransConvBlock, self).__init__()\n",
    "        \n",
    "        self.transconv = nn.Sequential(nn.ConvTranspose2d(in_channels, \n",
    "                                                          out_channels, \n",
    "                                                          kernel_size=k_size, \n",
    "                                                          stride=stride,  \n",
    "                                                          padding=padding),\n",
    "                                       nn.Conv2d(out_channels, \n",
    "                                             out_channels, \n",
    "                                             kernel_size=3, \n",
    "                                             stride=1, \n",
    "                                             padding=1),\n",
    "                                       nn.Dropout(p=0.1, inplace=False),\n",
    "                                       nn.BatchNorm2d(out_channels, track_running_stats=False),\n",
    "                                       nn.LeakyReLU()\n",
    "                                       )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.transconv(x)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class TransConvBlock_last(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, k_size=3, stride=2, padding=1):\n",
    "        super(TransConvBlock_last, self).__init__()\n",
    "        \n",
    "        self.transconv = nn.Sequential(nn.ConvTranspose2d(in_channels, \n",
    "                                                          out_channels, \n",
    "                                                          kernel_size=k_size, \n",
    "                                                          stride=stride, \n",
    "                                                          padding=padding),\n",
    "                                       nn.BatchNorm2d(out_channels, track_running_stats=False)\n",
    "                                       )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.transconv(x)\n",
    "        return out\n",
    "        \n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()    \n",
    "        \n",
    "        #encoder--------------------------------------------                                  \n",
    "        self.conv_block_1 = ConvBlock(12, 32, k_size=(3,1), stride=(2,1), padding=(1,0))      \n",
    "        self.conv_block_2 = ConvBlock(32, 64, k_size=(3,1), stride=(2,1), padding=(1,0)) \n",
    "        self.conv_block_3 = ConvBlock(64, 128, k_size=3, stride=2, padding=1)          \n",
    "        self.conv_block_4 = ConvBlock(128, 256, k_size=3, stride=2, padding=1)         \n",
    "        self.conv_block_5 = ConvBlock(256, 512, k_size=3, stride=2, padding=1)      \n",
    "        self.conv_block_6 = ConvBlock(512, 512, k_size=3, stride=2, padding=1)   \n",
    "        \n",
    "        #decoder-------------------------------------------     \n",
    "        self.trans_conv_block_1 = TransConvBlock(512, 256, k_size=(1,4), stride=(1,2), padding=(0,1))                \n",
    "        self.trans_conv_block_2 = TransConvBlock(256, 128, k_size=4, stride=2, padding=1)                \n",
    "        self.trans_conv_block_3 = TransConvBlock(128, 64, k_size=4, stride=2, padding=1)                \n",
    "        self.trans_conv_block_4 = TransConvBlock(64, 32, k_size=4, stride=2, padding=1)                      \n",
    "        self.trans_conv_block_5 = TransConvBlock_last(32, 1, k_size=3, stride=1, padding=1)                \n",
    "\n",
    "\n",
    "    def encode(self, x):\n",
    "       \n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.conv_block_2(x)\n",
    "        x = self.conv_block_3(x)\n",
    "        x = self.conv_block_4(x)\n",
    "        x = self.conv_block_5(x)    \n",
    "        out = self.conv_block_6(x)   \n",
    "        return out\n",
    "        \n",
    "        \n",
    "        \n",
    "    def decode(self, x):\n",
    "        \n",
    "        x = self.trans_conv_block_1(x)\n",
    "        x = self.trans_conv_block_2(x)\n",
    "        x = self.trans_conv_block_3(x)\n",
    "        x = self.trans_conv_block_4(x)\n",
    "        x = self.trans_conv_block_5(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.encode(x)\n",
    "        v_pred = self.decode(x)  \n",
    "        return v_pred\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd58d550-dabf-4916-9280-fd54e3a09c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "model = MyModel()\n",
    "inputs = (1,12, 1024, 256)\n",
    "summary(model, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca851c7f-5fda-403b-84ee-134d2fb08d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_tensor_norm = (vp_tensor - 2900)/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566971b4-dc44-40d4-be25-c233a6c68cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 7))\n",
    "gs = fig.add_gridspec(2, 2)\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"vp_tensor\")\n",
    "im = ax.imshow((vp_tensor[0].cpu().detach().numpy())/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "# 设置colorbar的取值范围\n",
    "vmin = (vp_tensor[0]/1000).min() # 最小值\n",
    "vmax = ((vp_tensor[0])/1000).max()   # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 1])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"vp_tensor_norm\")\n",
    "im = ax.imshow((vp_tensor_norm[0].cpu().detach().numpy()), extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "# 设置colorbar的取值范围\n",
    "vmin = (vp_tensor_norm[0]).min() # 最小值\n",
    "vmax = (vp_tensor_norm[0]).max() # 最大值\n",
    "im.set_clim(vmin, vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d12fd8-034b-4bb6-81ac-5190ba011d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "# torchvision.models.vgg16().features\n",
    "\n",
    "def train(model_Jin, data, wavelet, vi_tensor, optimizer, device='cpu'):\n",
    "    \n",
    "    data_resample = data[:, :, :, :] \n",
    "    data_norm = (data_resample-data.mean())/(data.std()).to(device)\n",
    "   \n",
    "    train_loss = 0\n",
    "    data_norm = data_norm.to(device)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    v_recon_norm = model_Jin(data_norm) \n",
    "    v_recon = (v_recon_norm)*(1000) + 2900  \n",
    "    v_recon = v_recon.to(device).type(dtype=torch.float32)\n",
    " \n",
    "    loss_fn2 = nn.MSELoss()\n",
    "    Loss2 = loss_fn2(v_recon[0], vi_tensor)\n",
    "    loss = Loss2\n",
    "    \n",
    "    train_loss += loss.detach().cpu().item()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return [train_loss], v_recon[0], data\n",
    "\n",
    "def save_state(epoch, model, optimizer, train_loss_history):\n",
    "    import os\n",
    "    state = {'epoch': epoch + 1,\n",
    "             'train_loss_history': train_loss_history,\n",
    "             'state_dict': model.state_dict(),\n",
    "             'optimizer': optimizer.state_dict()\n",
    "             }\n",
    "    torch.save(state, \"./checkpoints-Drop-marmousi-G-New-p0.1/checkpoint-Drop-pre-marmousi-G-2-{}.pth\".format(epoch+1))  #  2  track_running_stats=False\n",
    "    if os.path.exists(\"./checkpoints-Drop-marmousi-G-New-p0.1/checkpoint-Drop-pre-marmousi-G-2-{}.pth\".format(epoch)):\n",
    "        os.remove(\"./checkpoints-Drop-marmousi-G-New-p0.1/checkpoint-Drop-pre-marmousi-G-2-{}.pth\".format(epoch))\n",
    "        \n",
    "def load_state(model, optimizer, resume_file):\n",
    "    checkpoint = torch.load(resume_file)\n",
    "    resume_epoch = checkpoint['epoch']\n",
    "    train_loss_history = checkpoint['train_loss_history']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    return resume_epoch, model, optimizer, train_loss_history   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd001ae-8573-4c9e-bb6b-0bcd3b5c0b38",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "# 预训练模型\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "data = torch.load(\"./shots_marmousi_I_2048.npz\").to(device).type(dtype=torch.float32) \n",
    "\n",
    "model = MyModel().to(device)\n",
    "optimizer = torch.optim.Adam([{'params': model.parameters()}], \n",
    "                               lr=0.001, weight_decay=0.0001)\n",
    "\n",
    "max_epoch = 1000\n",
    "train_loss_history = []\n",
    "print_interval = 5\n",
    "for epoch in range(0, max_epoch):\n",
    "   \n",
    "    train_loss, v_pred, s_pred  = train(model, data, wavelet, vi_tensor, optimizer, device)\n",
    "    train_loss_history.append(train_loss)\n",
    "    save_state(epoch, model, optimizer, train_loss_history)\n",
    "   \n",
    "    if (epoch + 1) % print_interval == 0: \n",
    "        print(\"Epoch: {}, Training Loss: {:.8f}\".format(epoch, train_loss[0]))\n",
    "\n",
    "train_loss_history = torch.tensor(train_loss_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e80ad1-4d27-4455-a21c-d23620f77cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 7))\n",
    "gs = fig.add_gridspec(2, 2)\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"v_pred_full\")\n",
    "im = ax.imshow((v_pred[0].cpu().detach().numpy())/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "# 设置colorbar的取值范围\n",
    "vmin = (vi_tensor[0]/1000).min() # 最小值\n",
    "vmax = ((vi_tensor[0])/1000).max()   # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(gs[1, 0])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"vi\")\n",
    "im = ax.imshow(((vi_tensor[0]).cpu().detach().numpy() )/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(gs[1, 1])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"loss\")\n",
    "im = ax.imshow(((v_pred[0]-vi_tensor[0]).cpu().detach().numpy() )/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "\n",
    "# 设置colorbar的取值范围\n",
    "vmin = -((v_pred[0]-vi_tensor[0])/1000).max()  # 最小值\n",
    "vmax = ((v_pred[0]-vi_tensor[0])/1000).max()   # 最大值\n",
    "im.set_clim(vmin, vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe499d1-3dd6-465f-8e91-466cbb5beaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, wavelet, vp_tensor, optimizer, device='cpu'):\n",
    "    lamda1 = lamda2 = lamda3 = lamda4 = 1\n",
    "    model.train()\n",
    "    data_resample = data[:, :, :, :]\n",
    "    data_norm = (data_resample-data.mean())/(data.std()).to(device)\n",
    "    \n",
    "    train_loss = 0\n",
    "    Loss_val = 0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    v_recon_norm = model(data_norm) \n",
    "    v_recon = (v_recon_norm)*(1000) + 2900  \n",
    "    _, _, shots, _ = forward_rnn(vmodel = v_recon[0].to(device), segment_wavelet=wavelet)\n",
    "    shots_resample = shots[:, :, :, :]\n",
    "    \n",
    "    data_rgb = data_resample[0][:,None,].repeat(1, 3, 1, 1) \n",
    "    shots_rgb = shots_resample[0][:,None,].repeat(1, 3, 1, 1)  \n",
    "    data_rgb_norm = (data_rgb-data_rgb.mean())/(data_rgb.std())\n",
    "    shots_rgb_norm = (shots_rgb-data_rgb.mean())/(data_rgb.std())\n",
    "    data_vgg = model_vgg(data_rgb_norm)\n",
    "    shots_vgg = model_vgg(shots_rgb_norm)\n",
    "    \n",
    "    loss_fn1 = nn.L1Loss()\n",
    "    loss_fn2 = nn.MSELoss()\n",
    "   \n",
    "    Loss1 = loss_fn1(data_resample, shots_resample)\n",
    "    Loss2 = loss_fn2(data_resample, shots_resample)\n",
    "    L_recon_pixel = lamda1*Loss1 + lamda2*Loss2\n",
    "    \n",
    "    Loss3 = loss_fn1(data_vgg, shots_vgg)\n",
    "    Loss4 = loss_fn2(data_vgg, shots_vgg)\n",
    "    L_recon_perceptual = lamda3*Loss3 + lamda4*Loss4\n",
    "    \n",
    "    loss = L_recon_pixel + L_recon_perceptual\n",
    "    \n",
    "    train_loss += loss.detach().cpu().item()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    Loss_val = loss_fn2(v_recon[0], vp_tensor)\n",
    "    Loss_val += Loss_val.detach().cpu().item()\n",
    "    return [train_loss, L_recon_pixel, L_recon_perceptual, Loss_val], v_recon[0], shots, [data.min(), data.max()] \n",
    "    \n",
    "    \n",
    "def test(model, data, device='cpu'):\n",
    "    model.train()\n",
    "    data_resample = data[:, :, :, :] \n",
    "    data_norm = (data_resample-data.mean())/(data.std()).to(device)\n",
    "\n",
    "    v_recon_norm = model(data_norm) \n",
    "    v_recon = (v_recon_norm)*(1000) + 2900  \n",
    "    return v_recon[0]\n",
    "    \n",
    "def save_state(epoch, model, optimizer, train_loss_history):\n",
    "    import os\n",
    "    state = {'epoch': epoch + 1,\n",
    "             'train_loss_history': train_loss_history,\n",
    "             'state_dict': model.state_dict(),\n",
    "             'optimizer': optimizer.state_dict()\n",
    "             }\n",
    "    torch.save(state, \"./checkpoints-Drop-marmousi-G-New-p0.1/checkpoint-Drop-marmousi-G-2-{}.pth\".format(epoch+1))\n",
    "#     if os.path.exists(\"./checkpoints-Drop-marmousi-G-New-p0.1/checkpoint-Drop-marmousi-G-2-{}.pth\".format(epoch)):\n",
    "#         os.remove(\"./checkpoints-Drop-marmousi-G-New-p0.1/checkpoint-Drop-marmousi-G-2-{}.pth\"\".format(epoch))\n",
    "        \n",
    "def load_state(model, optimizer, resume_file):\n",
    "    checkpoint = torch.load(resume_file)\n",
    "    resume_epoch = checkpoint['epoch']\n",
    "    train_loss_history = checkpoint['train_loss_history']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    return resume_epoch, model, optimizer, train_loss_history   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2302f9-46b1-443b-a544-4dcb8bded06a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision\n",
    "\n",
    "# 训练模型\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "data = torch.load(\"./sho ts_marmousi_I_2048.npz\").to(device).type(dtype=torch.float32) \n",
    "\n",
    "model = MyModel().to(device)\n",
    "optimizer = torch.optim.Adam([{'params': model.parameters()}], \n",
    "                               lr=0.001, weight_decay=0.0001)\n",
    "_, model, _, _ = load_state(model, optimizer, \"./checkpoints-Drop-marmousi-G-New-p0.1/checkpoint-Drop-pre-marmousi-G-2-1000.pth\") \n",
    "optimizer = torch.optim.AdamW([{'params': model.parameters()}], \n",
    "                               lr=0.0001, betas=(0.9, 0.999), weight_decay=0.0001)\n",
    "model_vgg = torchvision.models.vgg16(pretrained=True).features[:13].to(device) #第13层输出--conv5的结果。\n",
    "\n",
    "max_epoch = 3000\n",
    "train_loss_history = [[], [], [], []] \n",
    "print_interval = 1\n",
    "# save_interval = 100\n",
    "for epoch in range(0, max_epoch):\n",
    "\n",
    "    train_loss, v_pred, s_pred, norm_list = train(model, data, wavelet, vp_tensor, optimizer, device)\n",
    "\n",
    "    for i in range(4):  \n",
    "        train_loss_history[i].append(train_loss[i]) \n",
    "   \n",
    "    if epoch == 0 or (epoch < 100 and (epoch + 1) % 10 == 0) or (epoch >= 100 and (epoch + 1) % 100 == 0):\n",
    "        save_state(epoch, model, optimizer, train_loss_history)\n",
    "        \n",
    "    if (epoch + 1) % print_interval == 0:\n",
    "        print(\"Epoch: {}, Training Loss: {:.8f}, recon_pixel Loss: {:.8f}, recon_perceptual Loss: {:.8f}, recon_vmodel Loss: {:.8f}\".format(epoch, train_loss[0], train_loss[1], train_loss[2], train_loss[3]))\n",
    "\n",
    "train_loss_history = torch.tensor(train_loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62299bc5-e80f-4b0a-9963-298e8921da8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, device='cpu'):\n",
    "    model.train()\n",
    "    data_resample = data[:, :, :, :] \n",
    "    data_norm = (data_resample-data.mean())/(data.std()).to(device)\n",
    "    \n",
    "    v_recon_norm = model(data_norm) \n",
    "    v_recon = (v_recon_norm)*(1000) + 2900  \n",
    "   \n",
    "    return v_recon[0]\n",
    "\n",
    "def test(model, data, device='cpu'):\n",
    "    model.eval()\n",
    "    data_resample = data[:, :, :, :] \n",
    "    data_norm = (data_resample-data.mean())/(data.std()).to(device)\n",
    "    \n",
    "    v_recon_norm = model(data_norm) \n",
    "    v_recon = (v_recon_norm)*(1000) + 2900  \n",
    "   \n",
    "    return v_recon[0]\n",
    "\n",
    "def load_state(model, optimizer, resume_file):\n",
    "    checkpoint = torch.load(resume_file)\n",
    "    resume_epoch = checkpoint['epoch']\n",
    "    train_loss_history = checkpoint['train_loss_history']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    return resume_epoch, model, optimizer, train_loss_history   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f45b94-325b-4d96-bca3-fdd107abf94e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 展示反演过程的vpred\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "data = torch.load(\"./shots_marmousi_I_2048.npz\").to(device).type(dtype=torch.float32)  \n",
    "model = MyModel().to(device)\n",
    "optimizer = torch.optim.AdamW([{'params': model.parameters()}], \n",
    "                               lr=0.00001, betas=(0.9, 0.999), weight_decay=0.0001)\n",
    "\n",
    "max_epoch = 3000\n",
    "for epoch in range(0, max_epoch):\n",
    "    if epoch == 0 or (epoch + 1) % 100 == 0:\n",
    "        _, model, _, _ = load_state(model, optimizer, \"./checkpoints-Drop-marmousi-G-New-p0.1/checkpoint-Drop-marmousi-G-2-{}.pth\".format(epoch+1)) \n",
    "        model = model.to(device)\n",
    "        v_pred = test(model, data, device)\n",
    "        \n",
    "        torch.save(v_pred, './Figures/Dropout-G-inversion-results/p0.1/v_pred_test/v_pred_{}.pth'.format(epoch+1))\n",
    "            \n",
    "        cmap = 'RdBu_r'\n",
    "        fig = plt.figure(figsize=(26, 10))\n",
    "        gs = fig.add_gridspec(3, 4)\n",
    "        ax = fig.add_subplot(gs[0, 0])\n",
    "        ax.set_ylabel('Depth (km)', fontsize=16)\n",
    "        #ax.set_xlabel('Distance (km)', fontsize=16)\n",
    "        ax.set_title('(a) {}'.format(epoch+1), loc='left', fontsize=20)\n",
    "        im = ax.imshow(v_pred.detach().cpu().numpy().squeeze(), extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap=cmap,\n",
    "                       vmin=v_pred.cpu().squeeze().min(), vmax=v_pred.cpu().squeeze().max())\n",
    "        ax.set_xticks([])\n",
    "        cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='$m/s$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c673514c-68f1-474f-84fe-9a509ca2d2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 汇总展示反演过程的vpred\n",
    "epochs = [1, 1000, 1500, 2000, 3000]\n",
    "v_pred = torch.zeros((5, 128, 256))\n",
    "for s in range(5):\n",
    "    epoch = epochs[s]\n",
    "    v_pred[s] = torch.load('./Figures/Dropout-G-inversion-results/p0.1/v_pred_test/v_pred_{}.pth'.format(epoch))\n",
    "# print(v_pred)  \n",
    "\n",
    "cmap = 'RdBu_r'\n",
    "fig = plt.figure(figsize=(30, 3))\n",
    "gs = fig.add_gridspec(1, 5)\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "ax.set_ylabel('Depth [km]', fontsize=16)\n",
    "ax.set_xlabel('Distance [km]', fontsize=16)\n",
    "ax.set_title('(a)', loc='center', fontsize=20)\n",
    "im = ax.imshow(v_pred[0].detach().cpu().numpy()/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap=cmap,\n",
    "               vmin=vp_tensor.min()/1000, vmax=vp_tensor.max()/1000)\n",
    "# ax.set_xticks([])\n",
    "ax.tick_params(axis='x', labelsize=12) \n",
    "ax.tick_params(axis='y', labelsize=12) \n",
    "# cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='$Km/s$')\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 1])\n",
    "#ax.set_ylabel('Depth (km)', fontsize=16)\n",
    "ax.set_xlabel('Distance [km]', fontsize=16)\n",
    "ax.set_title('(b)', loc='center', fontsize=20)\n",
    "im = ax.imshow(v_pred[1].detach().cpu().numpy()/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap=cmap,\n",
    "               vmin=vp_tensor.min()/1000, vmax=vp_tensor.max()/1000)\n",
    "ax.set_yticks([])\n",
    "# ax.set_xticks([])\n",
    "ax.tick_params(axis='x', labelsize=12) \n",
    "# cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='$Km/s$')\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 2])\n",
    "#ax.set_ylabel('Depth (km)', fontsize=16)\n",
    "ax.set_xlabel('Distance [km]', fontsize=16)\n",
    "ax.set_title('(c)', loc='center', fontsize=20)\n",
    "im = ax.imshow(v_pred[2].detach().cpu().numpy()/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap=cmap,\n",
    "               vmin=vp_tensor.min()/1000, vmax=vp_tensor.max()/1000)\n",
    "ax.set_yticks([])\n",
    "# ax.set_xticks([])\n",
    "ax.tick_params(axis='x', labelsize=12) \n",
    "# cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='$Km/s$')\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 3])\n",
    "#ax.set_ylabel('Depth (km)', fontsize=16)\n",
    "ax.set_xlabel('Distance [km]', fontsize=16)\n",
    "ax.set_title('(d)', loc='center', fontsize=20)\n",
    "im = ax.imshow(v_pred[3].detach().cpu().numpy()/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap=cmap,\n",
    "               vmin=vp_tensor.min()/1000, vmax=vp_tensor.max()/1000)\n",
    "ax.set_yticks([])\n",
    "# ax.set_xticks([])\n",
    "ax.tick_params(axis='x', labelsize=12) \n",
    "# cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='$Km/s$')\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 4])\n",
    "#ax.set_ylabel('Depth (km)', fontsize=16)\n",
    "ax.set_xlabel('Distance [km]', fontsize=16)\n",
    "ax.set_title('(e)', loc='center', fontsize=20)\n",
    "im = ax.imshow(v_pred[4].detach().cpu().numpy()/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap=cmap,\n",
    "               vmin=vp_tensor.min()/1000, vmax=vp_tensor.max()/1000)\n",
    "ax.set_yticks([])\n",
    "# ax.set_xticks([])\n",
    "ax.tick_params(axis='x', labelsize=12) \n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\")\n",
    "cbar.ax.tick_params(labelsize=12)  \n",
    "cbar.set_label('Km/s', size=14) \n",
    "\n",
    "plt.subplots_adjust(left=0.125,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.05,  \n",
    "                    hspace=0.4)\n",
    "\n",
    "plt.savefig('./Figures/Dropout-0.1-test-G-inversion-results.png', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d9f35c-1273-4ec5-90f5-3857e9ca0a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 汇总展示反演过程的vpred\n",
    "epochs = [1, 1000, 1500, 2000, 3000]\n",
    "v_pred = torch.zeros((5, 128, 256))\n",
    "for s in range(5):\n",
    "    epoch = epochs[s]\n",
    "    v_pred[s] = torch.load('./Figures/Dropout-G-inversion-results/p0.1/v_pred_train/v_pred_{}.pth'.format(epoch))\n",
    "# print(v_pred)  \n",
    "\n",
    "cmap = 'RdBu_r'\n",
    "fig = plt.figure(figsize=(30, 3))\n",
    "gs = fig.add_gridspec(1, 5)\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "ax.set_ylabel('Depth [km]', fontsize=16)\n",
    "ax.set_xlabel('Distance [km]', fontsize=16)\n",
    "ax.set_title('(a)', loc='center', fontsize=20)\n",
    "im = ax.imshow(v_pred[0].detach().cpu().numpy()/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap=cmap,\n",
    "               vmin=vp_tensor.min()/1000, vmax=vp_tensor.max()/1000)\n",
    "# ax.set_xticks([])\n",
    "ax.tick_params(axis='x', labelsize=12) \n",
    "ax.tick_params(axis='y', labelsize=12) \n",
    "# cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='$Km/s$')\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 1])\n",
    "#ax.set_ylabel('Depth (km)', fontsize=16)\n",
    "ax.set_xlabel('Distance [km]', fontsize=16)\n",
    "ax.set_title('(b)', loc='center', fontsize=20)\n",
    "im = ax.imshow(v_pred[1].detach().cpu().numpy()/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap=cmap,\n",
    "               vmin=vp_tensor.min()/1000, vmax=vp_tensor.max()/1000)\n",
    "ax.set_yticks([])\n",
    "# ax.set_xticks([])\n",
    "ax.tick_params(axis='x', labelsize=12) \n",
    "# cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='$Km/s$')\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 2])\n",
    "#ax.set_ylabel('Depth (km)', fontsize=16)\n",
    "ax.set_xlabel('Distance [km]', fontsize=16)\n",
    "ax.set_title('(c)', loc='center', fontsize=20)\n",
    "im = ax.imshow(v_pred[2].detach().cpu().numpy()/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap=cmap,\n",
    "               vmin=vp_tensor.min()/1000, vmax=vp_tensor.max()/1000)\n",
    "ax.set_yticks([])\n",
    "# ax.set_xticks([])\n",
    "ax.tick_params(axis='x', labelsize=12) \n",
    "# cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='$Km/s$')\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 3])\n",
    "#ax.set_ylabel('Depth (km)', fontsize=16)\n",
    "ax.set_xlabel('Distance [km]', fontsize=16)\n",
    "ax.set_title('(d)', loc='center', fontsize=20)\n",
    "im = ax.imshow(v_pred[3].detach().cpu().numpy()/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap=cmap,\n",
    "               vmin=vp_tensor.min()/1000, vmax=vp_tensor.max()/1000)\n",
    "ax.set_yticks([])\n",
    "# ax.set_xticks([])\n",
    "ax.tick_params(axis='x', labelsize=12) \n",
    "# cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='$Km/s$')\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 4])\n",
    "#ax.set_ylabel('Depth (km)', fontsize=16)\n",
    "ax.set_xlabel('Distance [km]', fontsize=16)\n",
    "ax.set_title('(e)', loc='center', fontsize=20)\n",
    "im = ax.imshow(v_pred[4].detach().cpu().numpy()/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap=cmap,\n",
    "               vmin=vp_tensor.min()/1000, vmax=vp_tensor.max()/1000)\n",
    "ax.set_yticks([])\n",
    "# ax.set_xticks([])\n",
    "ax.tick_params(axis='x', labelsize=12) \n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\")\n",
    "cbar.ax.tick_params(labelsize=12)  \n",
    "cbar.set_label('Km/s', size=14) \n",
    "\n",
    "plt.subplots_adjust(left=0.125,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.05,  \n",
    "                    hspace=0.4)\n",
    "\n",
    "plt.savefig('./Figures/Dropout-0.1-train-G-inversion-results.png', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f01f13-8525-4404-9af5-c04896463f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 展示反演过程的vpred\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "data = torch.load(\"./shots_marmousi_I_2048.npz\").to(device).type(dtype=torch.float32)  \n",
    "model = MyModel().to(device)\n",
    "optimizer = torch.optim.AdamW([{'params': model.parameters()}], \n",
    "                               lr=0.00001, betas=(0.9, 0.999), weight_decay=0.0001)\n",
    "\n",
    "_, model, _, train_loss_history = load_state(model, optimizer, \"./checkpoints-Drop-marmousi-G-New-p0.1/checkpoint-Drop-marmousi-G-2-{}.pth\".format(3000)) \n",
    "        \n",
    "train_loss_history = torch.tensor(train_loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd20900-2777-44fe-9a00-bb1c8f181312",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=3000\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.plot(np.arange(0,n), train_loss_history[0, 0:n].numpy(), label=\"all\")\n",
    "plt.plot(np.arange(0,n), train_loss_history[1, 0:n].numpy()*1000, label=\"recon_pixel\")\n",
    "plt.plot(np.arange(0,n), train_loss_history[2, 0:n].numpy(), label=\"recon_percep\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b2dfd3-879b-469b-8394-f3250ae47b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_loss_history, './Figures/Dropout_0.1_train_loss_history.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74216e96-489f-4dcd-998e-e8fd0e7029c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropout = 0.1 \n",
    "fig = plt.figure(figsize=(20, 14))\n",
    "gs = fig.add_gridspec(3, 2)\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"v_pred\")\n",
    "im = ax.imshow((v_pred[0].cpu().detach().numpy())/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "# 设置colorbar的取值范围\n",
    "vmin = ((vp_tensor[0])/1000).min()  # 最小值\n",
    "vmax = ((vp_tensor[0])/1000).max()  # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "# ax = fig.add_subplot(gs[0, 1])\n",
    "# ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"v_init\")\n",
    "# im = ax.imshow(((vi_tensor[0]).cpu().detach().numpy() )/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "# cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(gs[1, 1])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"vp\")\n",
    "im = ax.imshow(((vp_tensor[0]).cpu().detach().numpy() )/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "# 设置colorbar的取值范围\n",
    "vmin = ((vp_tensor[0])/1000).min()  # 最小值\n",
    "vmax = ((vp_tensor[0])/1000).max()  # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "\n",
    "ax = fig.add_subplot(gs[1, 0])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"vi\")\n",
    "im = ax.imshow(((vi_tensor[0]).cpu().detach().numpy() )/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "vmin = ((vp_tensor[0])/1000).min()  # 最小值\n",
    "vmax = ((vp_tensor[0])/1000).max()  # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "\n",
    "ax = fig.add_subplot(gs[2, 1])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"v_pred-vp\")\n",
    "im = ax.imshow(((v_pred[0]-vp_tensor[0]).cpu().detach().numpy() )/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "# 设置colorbar的取值范围\n",
    "vmin = -((v_pred[0]-vp_tensor[0])/1000).max()  # 最小值\n",
    "vmax = ((v_pred[0]-vp_tensor[0])/1000).max()   # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(gs[2, 0])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"v_pred-vi\")\n",
    "im = ax.imshow(((v_pred[0]-vi_tensor[0]).cpu().detach().numpy() )/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "# 设置colorbar的取值范围\n",
    "vmin = -((v_pred[0]-vi_tensor[0])/1000).max()   # 最小值\n",
    "vmax = ((v_pred[0]-vi_tensor[0])/1000).max()   # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdf79b6-00c0-4b92-8937-4294c455e0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=2000\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.plot(np.arange(0,n), train_loss_history[0, 0:n].numpy(), label=\"all\")\n",
    "plt.plot(np.arange(0,n), train_loss_history[1, 0:n].numpy()*1000, label=\"recon_pixel\")\n",
    "plt.plot(np.arange(0,n), train_loss_history[2, 0:n].numpy(), label=\"recon_percep\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e679cba4-e225-431a-aa52-7d91639f62fe",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n=2000\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.plot(np.arange(0,n), train_loss_history[3, 0:n].numpy(), label=\"recon_vp\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5141c576-662e-4cad-bdcc-070397b0323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.plot(np.arange(0,1024), s_pred[0, 6, :, 10].detach().cpu().numpy(), label=\"s_pred\")\n",
    "plt.plot(np.arange(0,1024), data[0, 6, :, 10].detach().cpu().numpy(), label=\"data\")\n",
    "plt.plot(np.arange(0,1024), (data[0, 6, :, 10]-s_pred[0, 6, :, 10]).detach().cpu().numpy(), label=\"loss\")\n",
    "\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3be0d7-894b-4a65-991b-f49b123e35ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24, 10))\n",
    "gs = fig.add_gridspec(1, 3)\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"s_pred\")\n",
    "im = ax.imshow((s_pred[0, 6].cpu().detach().numpy()), aspect=0.25, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "# 设置colorbar的取值范围\n",
    "vmin = ((data[0, 6])).min()/40   # 最小值\n",
    "vmax = ((data[0, 6])).max()/40   # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "# ax = fig.add_subplot(gs[0, 1])\n",
    "# ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"v_init\")\n",
    "# im = ax.imshow(((vi_tensor[0]).cpu().detach().numpy() )/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "# cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 1])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"data\")\n",
    "im = ax.imshow(((data[0, 6]).cpu().detach().numpy()), aspect=0.25, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "# 设置colorbar的取值范围\n",
    "vmin = ((data[0, 6])).min()/40  # 最小值\n",
    "vmax = ((data[0, 6])).max()/40  # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 2])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"loss\")\n",
    "im = ax.imshow(((data[0, 6]-s_pred[0, 6]).cpu().detach().numpy()), aspect=0.25, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "# 设置colorbar的取值范围\n",
    "vmin = -((data[0, 6]-s_pred[0, 6])).max()   # 最小值\n",
    "vmax = ((data[0, 6]-s_pred[0, 6])).max()   # 最大值\n",
    "im.set_clim(vmin, vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e32069-2c2e-4859-8d84-d4284d198b7e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 添加噪音"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0da9b4b-dba6-43ae-8102-b557c1bc04ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def add_noise_SNR(data, noise_ratio):\n",
    "    \"\"\"\n",
    "    This function adds white noise to the signal.\n",
    "    :param data: Input data (seismic recording). It should be a PyTorch tensor of shape (nt, nx).\n",
    "    :param noise_ratio: SNR value. It must be a non-negative real number.\n",
    "    :return: Signal with added noise.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate white noise\n",
    "    noise = torch.randn(data.size())\n",
    "\n",
    "    # Compute the power of signal and noise\n",
    "    original_signal_power = torch.pow(data, 2).mean()\n",
    "    noise_power = torch.pow(noise, 2).mean()\n",
    "\n",
    "    # Compute the scaling factor for noise\n",
    "    noise_scaling = ((original_signal_power / noise_power) / noise_ratio).sqrt()\n",
    "\n",
    "    # Add noise to the original signal\n",
    "    noised_data = data + noise_scaling * noise\n",
    "\n",
    "    return noised_data\n",
    "\n",
    "# 假设你的地震记录存储在一个名为seismic_record的Tensor中:\n",
    "seismic_record = torch.load(\"./shots_marmousi_I_2048.npz\").cpu()  #[1,12,1024,256]\n",
    "\n",
    "# 指定所需的信噪比:\n",
    "SNR = 10  # 假设你想要的信噪比为10\n",
    "\n",
    "# 使用函数添加白噪声到地震记录:\n",
    "seismic_record_noised = add_noise_SNR(seismic_record, SNR)\n",
    "torch.save(seismic_record_noised, \"./shots_marmousi_I_2048_SNR10.npz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b25c36-0830-4163-9b03-8894bfb59519",
   "metadata": {},
   "outputs": [],
   "source": [
    "seismic_record_noised.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f144e3ed-3e0f-44f9-87a7-6971dc1d8a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(seismic_record[0,0], vmin=-seismic_record.max()/40, vmax=seismic_record.max()/40,aspect=0.3, cmap='RdBu_r')\n",
    "plt.colorbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bda59d-d165-4cf8-ad60-61b6d31acaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(seismic_record_noised[0,0], vmin=-seismic_record.max()/40, vmax=seismic_record.max()/40,aspect=0.3, cmap='RdBu_r')\n",
    "plt.colorbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e37bed9-9c23-4867-874c-dddcd9d762b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def add_noise_std(data, ratio):\n",
    "    \"\"\"\n",
    "    input: pytorch tensor representing the signal\n",
    "    \"\"\"\n",
    "    # Calculate signal std\n",
    "    signal_std = torch.std(data)\n",
    "   \n",
    "    # Generate an sample of white noise\n",
    "    noise = torch.randn(data.size())*signal_std*ratio\n",
    "    \n",
    "    # Calculate \n",
    "    noised_data = data + noise\n",
    "    \n",
    "    return noised_data\n",
    "\n",
    "# 假设你的地震记录存储在一个名为seismic_record的Tensor中:\n",
    "seismic_record = torch.load(\"./shots_marmousi_I_2048.npz\").cpu()   #[1,12,1024,256]\n",
    "seismic_vi_record = torch.load(\"./shots_vi10_marmousi_I_2048.npz\").cpu()   #[1,12,1024,256]\n",
    "\n",
    "# 指定所需的信噪比:\n",
    "ratio = 1   # 假设你想要的比率\n",
    "\n",
    "# 使用函数添加白噪声到地震记录:\n",
    "seismic_record_noised = add_noise_std(seismic_record, ratio)\n",
    "seismic_vi_record_noised = add_noise_std(seismic_vi_record, ratio)\n",
    "\n",
    "torch.save(seismic_record_noised, \"./shots_marmousi_I_2048_STD1.npz\")\n",
    "torch.save(seismic_vi_record_noised, \"./shots_vi10_marmousi_I_2048_STD1.npz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cbc4ac-5ff4-4699-99dc-394fe4dffbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(seismic_record[0,0], vmin=-seismic_record.max()/40, vmax=seismic_record.max()/40,aspect=0.3, cmap='RdBu_r')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38613fb3-00e4-4035-9bd0-ad5e77a3e279",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(seismic_record_noised[0,0], vmin=-seismic_record.max()/40, vmax=seismic_record.max()/40,aspect=0.3, cmap='RdBu_r')\n",
    "plt.colorbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a13f87-c977-4bd2-b5a4-a45166a7cd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(seismic_vi_record_noised[0,0], vmin=-seismic_record.max()/40, vmax=seismic_record.max()/40,aspect=0.3, cmap='RdBu_r')\n",
    "plt.colorbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916ca52d-9166-4866-a1bc-f7d43e2babeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f278ce-e452-4c49-b4c2-a8ef2befc34c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fc737ab-9298-4e62-bdc4-5ec00c2e1af5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 缺失低频的反演"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2165270-db44-4788-b607-b5bebdde7235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, k_size=3, stride=1, padding=1):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(nn.Conv2d(in_channels, \n",
    "                                             out_channels, \n",
    "                                             kernel_size=k_size, \n",
    "                                             stride=stride, \n",
    "                                             padding=padding),\n",
    "                                   nn.BatchNorm2d(out_channels),\n",
    "                                   nn.LeakyReLU(),\n",
    "                                   nn.Dropout(p=0.1, inplace=False)\n",
    "                                  )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class TransConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, k_size=3, stride=2, padding=1):\n",
    "        super(TransConvBlock, self).__init__()\n",
    "        \n",
    "        self.transconv = nn.Sequential(nn.ConvTranspose2d(in_channels, \n",
    "                                                          out_channels, \n",
    "                                                          kernel_size=k_size, \n",
    "                                                          stride=stride, \n",
    "                                                          padding=padding),\n",
    "                                       nn.BatchNorm2d(out_channels),\n",
    "                                       nn.LeakyReLU(),\n",
    "                                       nn.Dropout(p=0.1, inplace=False)\n",
    "                                       )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.transconv(x)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class TransConvBlock_last(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, k_size=3, stride=2, padding=1):\n",
    "        super(TransConvBlock_last, self).__init__()\n",
    "        \n",
    "        self.transconv = nn.Sequential(nn.ConvTranspose2d(in_channels, \n",
    "                                                          out_channels, \n",
    "                                                          kernel_size=k_size, \n",
    "                                                          stride=stride, \n",
    "                                                          padding=padding),\n",
    "                                       # nn.Dropout(p=0.2, inplace=False),\n",
    "                                       nn.BatchNorm2d(out_channels)\n",
    "                                       )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.transconv(x)\n",
    "        return out\n",
    "        \n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()    \n",
    "        \n",
    "        #encoder--------------------------------------------                                   #[batch,6,1000,32]\n",
    "        self.conv_block_1 = ConvBlock(12, 32, k_size=(4,1), stride=(2,1), padding=(1,0))       #[batch,32,500,32]\n",
    "        \n",
    "        self.conv_block_2 = ConvBlock(32, 64, k_size=(4,1), stride=(2,1), padding=(1,0)) \n",
    "        \n",
    "        self.conv_block_3 = ConvBlock(64, 128, k_size=4, stride=2, padding=1)          \n",
    "        \n",
    "        self.conv_block_4 = ConvBlock(128, 256, k_size=4, stride=2, padding=1)         \n",
    "        \n",
    "        self.conv_block_5 = ConvBlock(256, 512, k_size=4, stride=2, padding=1)      \n",
    "        \n",
    "        self.conv_block_6 = ConvBlock(512, 512, k_size=4, stride=2, padding=1)   \n",
    "        \n",
    "        \n",
    "        #文章3--------------------------------------------     \n",
    "        self.trans_conv_block_1 = TransConvBlock(512, 256, k_size=(1,4), stride=(1,2), padding=(0,1))                \n",
    "        \n",
    "        self.trans_conv_block_2 = TransConvBlock(256, 128, k_size=4, stride=2, padding=1)                \n",
    "        \n",
    "        self.trans_conv_block_3 = TransConvBlock(128, 64, k_size=4, stride=2, padding=1)                \n",
    "        \n",
    "        self.trans_conv_block_4 = TransConvBlock(64, 32, k_size=4, stride=2, padding=1)                      \n",
    "        \n",
    "        self.trans_conv_block_5 = TransConvBlock_last(32, 1, k_size=3, stride=1, padding=1)                \n",
    "        \n",
    "        # self.tanh = nn.Tanh()\n",
    "        # self.relu = nn.ReLU()\n",
    "\n",
    "       \n",
    "\n",
    "    def encode(self, x):\n",
    "        # print(\"x1:\", x.shape)\n",
    "        x = self.conv_block_1(x)\n",
    "        # print(\"x2:\", x.shape)\n",
    "        x = self.conv_block_2(x)\n",
    "        # print(\"x3:\", x.shape)\n",
    "        x = self.conv_block_3(x)\n",
    "        # print(\"x4:\", x.shape)\n",
    "        x = self.conv_block_4(x)\n",
    "        # print(\"x5:\", x.shape)\n",
    "        x = self.conv_block_5(x)    \n",
    "        # print(\"x6:\", x.shape)\n",
    "        out = self.conv_block_6(x)     #[batch,512,1,1]\n",
    "        # print(\"x7:\", out.shape)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "        \n",
    "        \n",
    "    def decode(self, x):\n",
    "        # print(\"x1:\", x.shape) \n",
    "        x = self.trans_conv_block_1(x)\n",
    "        # print(\"x2:\", x.shape)\n",
    "        x = self.trans_conv_block_2(x)\n",
    "        # print(\"x3:\", x.shape)\n",
    "        x = self.trans_conv_block_3(x)\n",
    "        # print(\"x4:\", x.shape)\n",
    "        x = self.trans_conv_block_4(x)\n",
    "        # print(\"x5:\", x.shape)\n",
    "        x = self.trans_conv_block_5(x)\n",
    "        # print(\"x6:\", x.shape)\n",
    "        \n",
    "        # x = self.tanh(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.encode(x)\n",
    "        v_pred = self.decode(x)  \n",
    "        # v_pred = (torch.exp(v_pred)-0.8)/2\n",
    "        # v_pred_clamped = torch.clamp(v_pred, 0, 1)  #限定输出数值在[0,1]之间\n",
    "        # v_pred_clamped = torch.sqrt(v_pred_clamped)\n",
    "        return v_pred\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b736f49-010e-4e66-863b-bdfdfcadff22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "# torchvision.models.vgg16().features\n",
    "\n",
    "def train(model_Jin, data, wavelet, vi_tensor, optimizer, device='cpu'):\n",
    "    \n",
    "    data_resample = data[:, :, :, :]   #输入的是resample后的\n",
    "    data_norm = (data_resample-data.mean())/(data.std()).to(device)\n",
    "   \n",
    "    train_loss = 0\n",
    "    data_norm = data_norm.to(device)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    v_recon_norm = model_Jin(data_norm) \n",
    "    \n",
    "    v_recon = (v_recon_norm)*(1000) + 2900  \n",
    "    # v_recon = (v_recon_norm)*(5500-1500) + 1500  \n",
    "    # v_recon = (v_recon_norm)*(5309-1572) + 1572  \n",
    "    # print(v_recon.shape)\n",
    "    v_recon = v_recon.to(device).type(dtype=torch.float32)\n",
    "    # _, _, shots, _ = forward_rnn(vmodel=v_recon[0].to(device), segment_wavelet=wavelet)\n",
    "\n",
    "    # loss_fn1 = nn.L1Loss()\n",
    "    loss_fn2 = nn.MSELoss()\n",
    "   \n",
    "    # Loss1 = loss_fn1(v_recon, vi_tensor)\n",
    "    Loss2 = loss_fn2(v_recon[0], vi_tensor)\n",
    "    \n",
    "    loss = Loss2\n",
    "    \n",
    "    train_loss += loss.detach().cpu().item()\n",
    "    loss.backward()\n",
    "    \n",
    "    # # # 梯度裁剪\n",
    "    # max_norm = 0.5 # 设置梯度的最大范数\n",
    "    # torch.nn.utils.clip_grad_norm_(model_Jin.parameters(), max_norm)\n",
    "\n",
    "    optimizer.step()\n",
    "    \n",
    "    return [train_loss], v_recon[0], data\n",
    "\n",
    "def save_state(epoch, model, optimizer, train_loss_history):\n",
    "    import os\n",
    "    state = {'epoch': epoch + 1,\n",
    "             'train_loss_history': train_loss_history,\n",
    "             'state_dict': model.state_dict(),\n",
    "             'optimizer': optimizer.state_dict()\n",
    "             }\n",
    "    torch.save(state, \"./checkpoints-Drop-marmousi-woLF/checkpoint-Drop-pre-marmousi-without-low-fre-G-1-{}.pth\".format(epoch+1))\n",
    "    if os.path.exists(\"./checkpoints-Drop-marmousi-woLF/checkpoint-Drop-pre-marmousi-without-low-fre-G-1-{}.pth\".format(epoch)):\n",
    "        os.remove(\"./checkpoints-Drop-marmousi-woLF/checkpoint-Drop-pre-marmousi-without-low-fre-G-1-{}.pth\".format(epoch))\n",
    "        \n",
    "def load_state(model, optimizer, resume_file):\n",
    "    checkpoint = torch.load(resume_file)\n",
    "    resume_epoch = checkpoint['epoch']\n",
    "    train_loss_history = checkpoint['train_loss_history']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    return resume_epoch, model, optimizer, train_loss_history   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdac2f2a-7b0a-4119-8516-b1a727cacc25",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "# 训练模型\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "# data = torch.load(\"./shots_vi10_marmousi_I_2048.npz\").to(device).type(dtype=torch.float32)  #[1,12,1024,256]\n",
    "data = torch.load(\"./shots_wo_low6_marmousi_I_1024.npz\").to(device).type(dtype=torch.float32)  #[1,12,1024,256]\n",
    "\n",
    "model = MyModel().to(device)\n",
    "optimizer = torch.optim.Adam([{'params': model.parameters()}], \n",
    "                               lr=0.001, weight_decay=0.0001)\n",
    "\n",
    "max_epoch = 1000\n",
    "train_loss_history = []\n",
    "print_interval = 5\n",
    "for epoch in range(0, max_epoch):\n",
    "   \n",
    "    train_loss, v_pred, s_pred  = train(model, data, wavelet, vi_tensor, optimizer, device)\n",
    "    train_loss_history.append(train_loss)\n",
    "    save_state(epoch, model, optimizer, train_loss_history)\n",
    "   \n",
    "    if (epoch + 1) % print_interval == 0:  #取余数是否等于0\n",
    "        print(\"Epoch: {}, Training Loss: {:.8f}\".format(epoch, train_loss[0]))\n",
    "\n",
    "train_loss_history = torch.tensor(train_loss_history)\n",
    "\n",
    "\n",
    "#只有第一项loss是准确的，参与训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b541e7-f3a7-4145-93a4-e8d204781b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 7))\n",
    "gs = fig.add_gridspec(2, 2)\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"v_pred_full\")\n",
    "im = ax.imshow((v_pred[0].cpu().detach().numpy())/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "# 设置colorbar的取值范围\n",
    "vmin = (vi_tensor[0]/1000).min() # 最小值\n",
    "vmax = ((vi_tensor[0])/1000).max()   # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(gs[1, 0])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"vi\")\n",
    "im = ax.imshow(((vi_tensor[0]).cpu().detach().numpy() )/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(gs[1, 1])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"loss\")\n",
    "im = ax.imshow(((v_pred[0]-vi_tensor[0]).cpu().detach().numpy() )/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "\n",
    "# 设置colorbar的取值范围\n",
    "vmin = -((v_pred[0]-vi_tensor[0])/1000).max()  # 最小值\n",
    "vmax = ((v_pred[0]-vi_tensor[0])/1000).max()   # 最大值\n",
    "im.set_clim(vmin, vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7045d8-8461-43d3-851f-da8a4aefed6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmas = torch.tensor([1.0, 1.0]).type(torch.float32).to(device)\n",
    "# sigmas.requires_grad_ = True\n",
    "# False\n",
    "sigmas = torch.tensor([1.0, 1.0], requires_grad=False).type(torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "def train(model, data, wavelet, vp_tensor, optimizer, device='cpu'):\n",
    "    lamda1 = lamda2 = lamda3 = lamda4 = 1\n",
    "    model.train()\n",
    "    data_resample = data[:, :, :, :]   #输入的是resample后的\n",
    "    # data_norm = (data-data.min())/(data.max()-data.min()).to(device)\n",
    "    data_norm = (data_resample-data.mean())/(data.std()).to(device)\n",
    "    \n",
    "    train_loss = 0\n",
    "    Loss_val = 0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    v_recon_norm = model(data_norm)  #输出范围[-1,1]\n",
    "    v_recon = (v_recon_norm)*(1000) + 2900  \n",
    "    _, _, shots, _ = forward_rnn(vmodel = v_recon[0].to(device), segment_wavelet=wavelet)\n",
    "    shots_resample = shots[:, :, :, :]\n",
    "    # print(shots_resample.shape)\n",
    "    # shots = 2*(shots-data.min())/(data.max()-data.min()) - 1\n",
    "    # shots = (shots-data.min())/(data.max()-data.min())\n",
    "   \n",
    "    \n",
    "    data_rgb = data_resample[0][:,None,].repeat(1, 3, 1, 1)     #第二个参数表示通道数 [6,3,1000,70]\n",
    "    shots_rgb = shots_resample[0][:,None,].repeat(1, 3, 1, 1)  \n",
    "    # data_rgb_norm = (data_rgb-data_rgb.min())/(data_rgb.max()-data_rgb.min())  #网络的输入正则化\n",
    "    # shots_rgb_norm = (shots_rgb-data_rgb.min())/(data_rgb.max()-data_rgb.min())\n",
    "    data_rgb_norm = (data_rgb-data_rgb.mean())/(data_rgb.std())  #网络的输入正则化\n",
    "    shots_rgb_norm = (shots_rgb-data_rgb.mean())/(data_rgb.std())\n",
    "    # print(shots_rgb_norm.shape)\n",
    "    data_vgg = model_vgg(data_rgb_norm)\n",
    "    shots_vgg = model_vgg(shots_rgb_norm)\n",
    "    # print(\"data_vgg:\", data_vgg.shape)\n",
    "    # print(\"data:\", data_rgb.shape)\n",
    "    # print(\"shots_vgg:\", shots_vgg.shape)\n",
    "    # print(\"v_recon:\", v_recon.shape)\n",
    "    \n",
    "    # L_recon_pixel = msle(data, shots)\n",
    "    # L_recon_perceptual = msle(data_vgg, shots_vgg)\n",
    "   \n",
    "    \n",
    "    loss_fn1 = nn.L1Loss()\n",
    "    loss_fn2 = nn.MSELoss()\n",
    "   \n",
    "    Loss1 = loss_fn1(data_resample, shots_resample)\n",
    "    Loss2 = loss_fn2(data_resample, shots_resample)\n",
    "    L_recon_pixel = lamda1*Loss1 + lamda2*Loss2\n",
    "    \n",
    "    Loss3 = loss_fn1(data_vgg, shots_vgg)\n",
    "    Loss4 = loss_fn2(data_vgg, shots_vgg)\n",
    "    L_recon_perceptual = lamda3*Loss3 + lamda4*Loss4\n",
    "    \n",
    "    # 动态调整权重系数\n",
    "    # sigmas0 = 1 / (1 + torch.exp(-L_recon_pixel))  # 可以根据具体需求调整计算方式\n",
    "    # sigmas1 = 1 / (1 + torch.exp(-L_recon_perceptual))  # 可以根据具体需求调整计算方式\n",
    "        \n",
    "    # loss = L_recon_pixel + L_recon_perceptual\n",
    "    loss = L_recon_pixel/(2*sigmas[0]*sigmas[0]) + torch.log(sigmas[0]) + L_recon_perceptual/(2*sigmas[1]*sigmas[1]) + torch.log(sigmas[1]) #+ KLD/1000*(2*sigmas[2]) + torch.log(sigmas[2]) \n",
    "    # loss = L_recon_pixel/(2*sigmas[0]*sigmas[0]) + torch.log(sigmas[0])\n",
    "    \n",
    "    train_loss += loss.detach().cpu().item()\n",
    "    loss.backward()\n",
    "    \n",
    "     # 梯度裁剪\n",
    "    # max_norm = 0.0001 # 设置梯度的最大范数\n",
    "    # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    # loss_fn2 = nn.MSELoss()\n",
    "    Loss_val = loss_fn2(v_recon[0], vp_tensor)\n",
    "    Loss_val += Loss_val.detach().cpu().item()\n",
    "    return [train_loss, L_recon_pixel, L_recon_perceptual, Loss_val], v_recon[0], shots, [data.min(), data.max()] #, data_true, mu, logvar\n",
    "    # return [train_loss, loss_recon, loss_recon2], v_recon_f/ull, shots #, data_true, mu, logvar\n",
    "    # return [train_loss, loss_recon, loss_recon2, KLD], v_recon_full, shots, data_true, mu, logvar\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def test(model, data, device='cpu'):\n",
    "    model.train()\n",
    "    data_resample = data[:, :, :, :]   #输入的是resample后的\n",
    "    data_norm = (data_resample-data.mean())/(data.std()).to(device)\n",
    "\n",
    "    v_recon_norm = model(data_norm)  #输出范围[-1,1]\n",
    "    v_recon = (v_recon_norm)*(1000) + 2900  \n",
    "    \n",
    "    return v_recon[0]\n",
    "    \n",
    "  \n",
    "    \n",
    "def save_state(epoch, model, optimizer, train_loss_history):\n",
    "    import os\n",
    "    state = {'epoch': epoch + 1,\n",
    "             'train_loss_history': train_loss_history,\n",
    "             'state_dict': model.state_dict(),\n",
    "             'optimizer': optimizer.state_dict()\n",
    "             }\n",
    "    torch.save(state, \"./checkpoints-Drop-marmousi-woLF/checkpoint-Drop-marmousi-without-low-fre-G-1-{}.pth\".format(epoch+1))\n",
    "#     if os.path.exists(\"./checkpoints-Drop-marmousi-woLF/checkpoint-Drop-marmousi-without-low-fre-G-1-{}.pth\".format(epoch)):\n",
    "#         os.remove(\"./checkpoints-Drop-marmousi-woLF/checkpoint-Drop-marmousi-without-low-fre-G-1-{}.pth\".format(epoch))\n",
    "        \n",
    "def load_state(model, optimizer, resume_file):\n",
    "    checkpoint = torch.load(resume_file)\n",
    "    resume_epoch = checkpoint['epoch']\n",
    "    train_loss_history = checkpoint['train_loss_history']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    return resume_epoch, model, optimizer, train_loss_history   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a025c5c-bfa6-4231-a9c2-f2c3508ca4f2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision\n",
    "\n",
    "# 训练模型\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "data = torch.load(\"./shots_wo_low6_marmousi_I_1024.npz\").to(device).type(dtype=torch.float32)  #[1,12,1024,256]\n",
    "\n",
    "model = MyModel().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam([{'params': model.parameters()}], \n",
    "                               lr=0.001, weight_decay=0.0001)\n",
    "_, model, _, _ = load_state(model, optimizer, \"./checkpoints-Drop-marmousi-woLF/checkpoint-Drop-pre-marmousi-without-low-fre-G-1-1000.pth\") \n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW([{'params': model.parameters()}, {'params':sigmas}], \n",
    "                               lr=0.0001, betas=(0.9, 0.999), weight_decay=0.0001)\n",
    "# 定义学习率调度器，设置每经过10个epoch时，学习率衰减为原来的10%\n",
    "# scheduler = StepLR(optimizer, step_size=1000, gamma=0.1)\n",
    "\n",
    "model_vgg = torchvision.models.vgg16(pretrained=True).features[:13].to(device) #第13层输出--conv5的结果。\n",
    "\n",
    "max_epoch = 2000\n",
    "# train_loss_history = []\n",
    "train_loss_history = [[], [], [], []]  # 初始化4个列表，分别表示4列\n",
    "print_interval = 10\n",
    "save_interval = 100\n",
    "for epoch in range(0, max_epoch):\n",
    "    # 在每个epoch之前更新学习率\n",
    "    # scheduler.step()\n",
    "    train_loss, v_pred, s_pred, norm_list = train(model, data, wavelet, vp_tensor, optimizer, device)\n",
    "    for i in range(4):  # 假设train_loss始终包含4个元素\n",
    "        train_loss_history[i].append(train_loss[i])  # 将每个元素添加到对应列的列表\n",
    "        \n",
    "    # 每100个epochs，保存一次模型状态\n",
    "    if epoch == 0 or (epoch + 1) % save_interval == 0:    \n",
    "        save_state(epoch, model, optimizer, train_loss_history)\n",
    "    \n",
    "    if (epoch + 1) % print_interval == 0:  #取余数是否等于0\n",
    "        print(\"Epoch: {}, Training Loss: {:.8f}, recon_pixel Loss: {:.8f}, recon_perceptual Loss: {:.8f}, recon_vmodel Loss: {:.8f}, sigmas0: {:.8f}, sigmas1: {:.8f}\".format(epoch, train_loss[0], train_loss[1], train_loss[2], train_loss[3], sigmas[0], sigmas[1]))\n",
    "\n",
    "train_loss_history = torch.tensor(train_loss_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643fc5e4-5a1e-4ba4-9589-3a26bca148f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_history.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3c4813-2281-43df-9dab-8db960a89ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=1000\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.plot(np.arange(0,n), train_loss_history[0, 0:n].numpy(), label=\"all\")\n",
    "plt.plot(np.arange(0,n), train_loss_history[1, 0:n].numpy()*100, label=\"recon_pixel\")\n",
    "plt.plot(np.arange(0,n), train_loss_history[2, 0:n].numpy(), label=\"recon_percep\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbe770a-11d1-42bf-9e6c-1e2299c433e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_his_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9698a2-92de-48a9-a5c9-fbc0f0d1a361",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=1000\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 1, 1)\n",
    "# plt.plot(np.arange(1,5000), train_loss_history[1:5000, 0].numpy(), label=\"all\")\n",
    "# plt.plot(np.arange(1,1000), train_loss_history[1:1000, 1].numpy(), label=\"recon_pixel\")\n",
    "# plt.plot(np.arange(1,1000), train_loss_history[1:1000, 2].numpy(), label=\"recon_percep\")\n",
    "plt.plot(np.arange(0,n), train_loss_history[0, 0:n].numpy(), label=\"recon_vp\")\n",
    "\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662f9007-60c7-4118-9220-72ed45346f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropout = 0.1   wo-low-fre6\n",
    "\n",
    "fig = plt.figure(figsize=(20, 14))\n",
    "gs = fig.add_gridspec(3, 2)\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"v_pred\")\n",
    "im = ax.imshow((v_pred[0].cpu().detach().numpy())/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "# 设置colorbar的取值范围\n",
    "vmin = ((vp_tensor[0])/1000).min()  # 最小值\n",
    "vmax = ((vp_tensor[0])/1000).max()  # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "# ax = fig.add_subplot(gs[0, 1])\n",
    "# ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"v_init\")\n",
    "# im = ax.imshow(((vi_tensor[0]).cpu().detach().numpy() )/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "# cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(gs[1, 1])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"vp\")\n",
    "im = ax.imshow(((vp_tensor[0]).cpu().detach().numpy() )/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "# 设置colorbar的取值范围\n",
    "vmin = ((vp_tensor[0])/1000).min()  # 最小值\n",
    "vmax = ((vp_tensor[0])/1000).max()  # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "\n",
    "ax = fig.add_subplot(gs[1, 0])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"vi\")\n",
    "im = ax.imshow(((vi_tensor[0]).cpu().detach().numpy() )/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "vmin = ((vp_tensor[0])/1000).min()  # 最小值\n",
    "vmax = ((vp_tensor[0])/1000).max()  # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "\n",
    "ax = fig.add_subplot(gs[2, 1])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"v_pred-vp\")\n",
    "im = ax.imshow(((v_pred[0]-vp_tensor[0]).cpu().detach().numpy() )/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "# 设置colorbar的取值范围\n",
    "vmin = -((v_pred[0]-vp_tensor[0])/1000).max()  # 最小值\n",
    "vmax = ((v_pred[0]-vp_tensor[0])/1000).max()   # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(gs[2, 0])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"v_pred-vi\")\n",
    "im = ax.imshow(((v_pred[0]-vi_tensor[0]).cpu().detach().numpy() )/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=1, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\", ctitle='km/s')\n",
    "\n",
    "# 设置colorbar的取值范围\n",
    "vmin = -((v_pred[0]-vi_tensor[0])/1000).max()   # 最小值\n",
    "vmax = ((v_pred[0]-vi_tensor[0])/1000).max()   # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c33ec2-c51f-4d14-aaaa-e0b17c075184",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "data = torch.load(\"./shots_wo_low6_marmousi_I_1024.npz\").to(device).type(dtype=torch.float32)  #[1,12,1024,256]\n",
    "\n",
    "model = MyModel().to(device)\n",
    "optimizer = torch.optim.AdamW([{'params': model.parameters()}, {'params':sigmas}], \n",
    "                               lr=0.0001, betas=(0.9, 0.999), weight_decay=0.0001)\n",
    "\n",
    "# _, model, _, _ = load_state(model, optimizer, \"./checkpoint-Drop-marmousi-without-low-fre-1-1000.pth\") \n",
    "_, model, _, _ = load_state(model, optimizer, \"./checkpoints-Drop-marmousi-woLF/checkpoint-Drop-marmousi-without-low-fre-G-1-2000.pth\") \n",
    "\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da01503-2e33-4717-b85d-f47f7ff9898f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data, device='cpu'):\n",
    "    model.train()\n",
    "    data_resample = data[:, :, :, :]   #输入的是resample后的\n",
    "    data_norm = (data_resample-data.mean())/(data.std()).to(device)\n",
    "\n",
    "    v_recon_norm = model(data_norm)  #输出范围[-1,1]\n",
    "    v_recon = (v_recon_norm)*(1000) + 2900  \n",
    "    \n",
    "    return v_recon[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1a5bc4-c06d-4614-bbce-ce25ba365fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 100\n",
    "v_samp = torch.zeros((samples, 128, 256))\n",
    "for s in range(samples):\n",
    "    v_pred = test(model, data, device)\n",
    "    v_samp[s] = v_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d254bf-2beb-4863-b53a-234ed555c68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#p=0.1 缺失低频\n",
    "fig = plt.figure(figsize=(21, 9.5))\n",
    "gs = fig.add_gridspec(2, 2)\n",
    "fontsize=16\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "# ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"v_pred_mean\")\n",
    "im = ax.imshow((torch.mean(v_samp, axis=0).cpu().detach().numpy())/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=0.8, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\")\n",
    "cbar.ax.set_title('km/s', size=fontsize)\n",
    "cbar.ax.tick_params(labelsize=fontsize)\n",
    "# 设置colorbar的取值范围\n",
    "vmin = ((vp_tensor[0])/1000).min()  # 最小值\n",
    "vmax = ((vp_tensor[0])/1000).max()  # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "ax.set_xlabel(\"Distance x[km]\", fontsize=fontsize)\n",
    "ax.set_title('v_pred_mean', fontsize=fontsize)\n",
    "ax.set_ylabel(\"Depth z[km]\",fontsize=fontsize)\n",
    "ax.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 1])\n",
    "# ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"v_pred_std\")\n",
    "im = ax.imshow((torch.std(v_samp/1000, axis=0).cpu().detach().numpy()), extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=0.8, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\")\n",
    "cbar.ax.set_title('km/s', size=fontsize)\n",
    "cbar.ax.tick_params(labelsize=fontsize)\n",
    "# 设置colorbar的取值范围\n",
    "vmin = 0  # 最小值\n",
    "vmax = ((torch.std(v_samp/1000, axis=0))).max()  # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "ax.set_xlabel(\"Distance x[km]\", fontsize=fontsize)\n",
    "ax.set_title('v_pred_std', fontsize=fontsize)\n",
    "ax.set_ylabel(\"Depth z[km]\",fontsize=fontsize)\n",
    "ax.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(gs[1, 0])\n",
    "# ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"vp_tensor\")\n",
    "im = ax.imshow((vp_tensor[0].cpu().detach().numpy())/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=0.8, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\")\n",
    "cbar.ax.set_title('km/s', size=fontsize)\n",
    "cbar.ax.tick_params(labelsize=fontsize)\n",
    "# 设置colorbar的取值范围\n",
    "vmin = ((vp_tensor[0])/1000).min()  # 最小值\n",
    "vmax = ((vp_tensor[0])/1000).max()  # 最大值\n",
    "im.set_clim(vmin, vmax)\n",
    "ax.set_xlabel(\"Distance x[km]\", fontsize=fontsize)\n",
    "ax.set_title('vp', fontsize=fontsize)\n",
    "ax.set_ylabel(\"Depth z[km]\",fontsize=fontsize)\n",
    "ax.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(gs[1, 1])\n",
    "ax.set(ylabel=\"Depth z[km]\", xlabel=\"Distance x[km]\", title=\"vp-v_pred_mean\")\n",
    "im = ax.imshow(((vp_tensor[0].cpu()-torch.mean(v_samp, axis=0).cpu()).detach().numpy())/1000, extent=[0, nx*dz/1000, nz*dz/1000, 0], aspect=0.8, cmap='RdBu_r')\n",
    "cbar = add_colorbar(ax, im, ax.transAxes, width=\"3%\")\n",
    "cbar.ax.set_title('km/s', size=fontsize)\n",
    "cbar.ax.tick_params(labelsize=fontsize)\n",
    "# cbar.set_label('km/s', size=fontsize)\n",
    "# 设置colorbar的取值范围\n",
    "vmin = -2.8412\n",
    "vmax = 2.8412\n",
    "im.set_clim(vmin, vmax)\n",
    "ax.set_xlabel(\"Distance x[km]\", fontsize=fontsize)\n",
    "ax.set_title('vp-v_pred_mean', fontsize=fontsize)\n",
    "ax.set_ylabel(\"Depth z[km]\",fontsize=fontsize)\n",
    "ax.tick_params(axis='both', which='major', labelsize=fontsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2489189-7326-49f4-85c2-d3e3cb04de04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
